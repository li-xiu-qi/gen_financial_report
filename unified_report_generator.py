"""
ç»Ÿä¸€çš„æŠ¥å‘Šç”Ÿæˆå™¨
åˆå¹¶äº†åŸºç¡€ç±»å’Œå…·ä½“å®ç°ï¼Œç®€åŒ–é¡¹ç›®ç»“æ„
"""

import os
import json
import re
import asyncio
import traceback
import time
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional, Awaitable, Callable
from concurrent.futures import ThreadPoolExecutor
from dotenv import load_dotenv

# å¯¼å…¥å¿…è¦çš„å·¥å…·å’Œæ¨¡å—
from financial_report.utils.calculate_tokens import TransformerTokenCalculator
from financial_report.utils.chat import chat_no_tool
from financial_report.llm_calls.text2infographic_html import text2infographic_html
from financial_report.utils.html2png import html2png
from financial_report.search_tools.search_tools import bing_search_with_cache

# å¯¼å…¥æç¤ºè¯æ¨¡æ¿
from report_prompts import (
    COMPANY_SECTION_WITH_DATA_PROMPT,
    COMPANY_SECTION_WITHOUT_DATA_PROMPT,
    SECTION_CHART_ENHANCEMENT_PROMPT,
    INDUSTRY_SECTION_WITH_DATA_PROMPT, 
    INDUSTRY_SECTION_WITHOUT_DATA_PROMPT,
    MACRO_SECTION_WITH_DATA_PROMPT,
    MACRO_SECTION_WITHOUT_DATA_PROMPT
)


# ====================
# åŸºç¡€æ•°æ®å¤„ç†å™¨
# ====================

class ReportDataProcessor:
    """ç»Ÿä¸€çš„æŠ¥å‘Šæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        self.token_calculator = TransformerTokenCalculator(model_name="deepseek-ai/DeepSeek-V3-0324")
    
    def load_report_data(self, data_dir: str, images_directory: str = None) -> Dict[str, Any]:
        """
        åŠ è½½æŠ¥å‘Šæ‰€éœ€çš„æ‰€æœ‰æ•°æ®
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            images_directory: å›¾ç‰‡ç›®å½•è·¯å¾„
            
        Returns:
            åŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸
        """
        print("ğŸ“‚ å¼€å§‹åŠ è½½æŠ¥å‘Šæ•°æ®æ–‡ä»¶...")
        data = {}
        
        # æ ¸å¿ƒæ•°æ®æ–‡ä»¶æ˜ å°„ - æ ¹æ®å®é™…çš„æ•°æ®æ–‡ä»¶
        core_files = {
            'outline': ['company_outline.json', 'industry_outline.json', 'macro_outline.json'],
            'allocation': ['outline_data_allocation.json'],
            'flattened_data': ['flattened_company_data.json', 'flattened_industry_data.json', 'flattened_macro_data.json'],
            'visualization_results': ['visualization_data_results.json']  # å¯è§†åŒ–å¤„ç†ç»“æœæ–‡ä»¶
        }
  
        # åŠ è½½æ ¸å¿ƒæ–‡ä»¶
        for key, possible_files in core_files.items():
            loaded = False
            for filename in possible_files:
                file_path = os.path.join(data_dir, filename)
                if os.path.exists(file_path):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = json.load(f)
                            data[key] = content
                            print(f"âœ“ å·²åŠ è½½æ ¸å¿ƒæ–‡ä»¶: {filename}")
                            loaded = True
                            break
                    except Exception as e:
                        print(f"âœ— åŠ è½½ {filename} å¤±è´¥: {e}")
            
            # å¯¹äºå¯è§†åŒ–ç»“æœæ–‡ä»¶ï¼Œå¯ä»¥æ˜¯å¯é€‰çš„
            if not loaded and key == 'visualization_results':
                print(f"â„¹ æœªæ‰¾åˆ°å¯è§†åŒ–ç»“æœæ–‡ä»¶ï¼ŒæŠ¥å‘Šå°†ä¸åŒ…å«å›¾è¡¨")
                continue
            elif not loaded:
                raise FileNotFoundError(f"æœªæ‰¾åˆ° {key} çš„ä»»ä½•å¯ç”¨æ–‡ä»¶: {possible_files}")
        
        # å¤„ç†å¯è§†åŒ–æ•°æ®
        if 'visualization_results' in data:
            if images_directory:
                data['visualizations'] = self._process_visualization_results(data['visualization_results'], images_directory)
                print("âœ“ å·²å¤„ç†å¯è§†åŒ–ç»“æœæ–‡ä»¶")
            else:
                print("âš  æœªæŒ‡å®šå›¾ç‰‡ç›®å½•ï¼Œå¯è§†åŒ–åŠŸèƒ½å¯èƒ½å—é™")
        else:
            print("â„¹ æœªæ‰¾åˆ°å¯è§†åŒ–ç»“æœæ–‡ä»¶ï¼ŒæŠ¥å‘Šå°†ä¸åŒ…å«å›¾è¡¨")
        
        # æ ‡å‡†åŒ–æ•°æ®ç»“æ„
        data = self._standardize_data_structure(data)
        
        return data
    
    def _process_visualization_results(self, results_data: Dict[str, Any], images_directory: str) -> Dict[str, Any]:
        """
        å¤„ç†å¯è§†åŒ–ç»“æœæ–‡ä»¶ï¼ˆæ–°çš„æ•°æ®ç»“æ„ï¼‰
        
        Args:
            results_data: å¯è§†åŒ–å¤„ç†ç»“æœæ•°æ®
            images_directory: å›¾ç‰‡ç›®å½•è·¯å¾„
            
        Returns:
            å¤„ç†åçš„å¯è§†åŒ–æ•°æ®
        """
        print("ğŸ”„ å¤„ç†å¯è§†åŒ–ç»“æœæ–‡ä»¶...")
        
        # æå–å¤„ç†æ‘˜è¦å’Œå»ºè®®åˆ—è¡¨
        processing_summary = results_data.get("processing_summary", {})
        processed_suggestions = results_data.get("processed_suggestions", [])
        
        print(f"   ğŸ“Š æ‰¾åˆ° {len(processed_suggestions)} ä¸ªå¯è§†åŒ–å»ºè®®")
        print(f"   ğŸ¯ ç›®æ ‡åç§°: {processing_summary.get('company_name', 'unknown')}")
        print(f"   âœ… æˆåŠŸå›¾è¡¨: {processing_summary.get('successful_count', 0)}")
        print(f"   âŒ å¤±è´¥å›¾è¡¨: {processing_summary.get('failed_count', 0)}")
        
        # å¤„ç†å›¾è¡¨æ•°æ®ï¼Œåªä¿ç•™æˆåŠŸç”Ÿæˆçš„å›¾è¡¨
        final_suggestions = []
        
        for suggestion in processed_suggestions:
            # åªå¤„ç†æˆåŠŸç”Ÿæˆçš„å›¾è¡¨
            if not suggestion.get("success", False):
                continue
                
            # è·å–PNGè·¯å¾„ - é€‚é…æ–°çš„å­—æ®µå
            png_path = (suggestion.get("chart_png_path", "") or 
                       suggestion.get("png_path", ""))
            
            if png_path and images_directory:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿®å¤è·¯å¾„
                if not os.path.exists(png_path):
                    # å°è¯•ä»images_directoryä¸­æ‰¾åˆ°æ–‡ä»¶
                    filename = os.path.basename(png_path)
                    corrected_path = os.path.join(images_directory, filename)
                    if os.path.exists(corrected_path):
                        png_path = corrected_path
                        print(f"   ğŸ”§ ä¿®å¤PNGè·¯å¾„: {filename}")
            
            # æ„å»ºå›¾è¡¨ä¿¡æ¯ï¼Œä¿æŒä¸åŸæ ¼å¼çš„å…¼å®¹æ€§
            chart_info = {
                "success": suggestion.get("success", False),
                "chart_title": suggestion.get("chart_title", ""),
                "chart_type": suggestion.get("visualization_type", suggestion.get("chart_type", "")),
                "section": suggestion.get("section", "æœªåˆ†ç±»"),
                "report_value": suggestion.get("report_value", "æ•°æ®å±•ç¤º"),
                "priority": suggestion.get("priority", "medium"),
                "reason": suggestion.get("reason", ""),
                "image_description": suggestion.get("image_description", ""),
                "png_path": png_path,
                "has_png": suggestion.get("has_png", bool(png_path and os.path.exists(png_path))),
                "data_source_ids": suggestion.get("data_ids", suggestion.get("data_source_ids", [])),
                "raw_data_count": suggestion.get("raw_data_count", 0),
                "references": suggestion.get("references", []),
                "created_at": suggestion.get("created_at", ""),
                "processing_time": suggestion.get("processing_time", ""),
                "file_size": suggestion.get("file_size", 0),
                "timestamp": suggestion.get("timestamp", "")
            }
            
            final_suggestions.append(chart_info)
        
        # æ„å»ºæœ€ç»ˆçš„å¯è§†åŒ–æ•°æ®ç»“æ„
        visualization_data = {
            "processing_summary": processing_summary,
            "processed_suggestions": final_suggestions,
            "metadata": {
                "total_suggestions": len(processed_suggestions),
                "successful_charts": len(final_suggestions),
                "failed_charts": len(processed_suggestions) - len(final_suggestions),
                "target_name": processing_summary.get("company_name", processing_summary.get("target_name", "")),
                "processing_time": processing_summary.get("processing_time", "")
            }
        }
        
        print(f"   âœ… å¯è§†åŒ–ç»“æœå¤„ç†å®Œæˆï¼Œæœ€ç»ˆå¯ç”¨å›¾è¡¨: {len(final_suggestions)}")
        return visualization_data
    
    def _standardize_data_structure(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–æ•°æ®ç»“æ„ï¼Œé€‚é…æ–°çš„æ•°æ®æ ¼å¼"""
        # æ ‡å‡†åŒ–å¤§çº²æ•°æ®ç»“æ„
        if 'outline' in data:
            outline_data = data['outline']
            # é€‚é…æ–°çš„æ•°æ®æ ¼å¼ï¼šç›´æ¥åŒ…å«reportOutlineçš„ç»“æ„
            if "reportOutline" in outline_data:
                data['outline'] = {"outline": outline_data["reportOutline"]}
            elif isinstance(outline_data, list):
                data['outline'] = {"outline": outline_data}
            elif "outline" not in outline_data and isinstance(outline_data, dict):
                # å¦‚æœæ˜¯ç›´æ¥çš„outlineæ•°æ®ï¼ŒåŒ…è£…ä¸€ä¸‹
                if any(key in outline_data for key in ["companyName", "companyCode"]):
                    # ä¿æŒåŸæœ‰ç»“æ„
                    pass
                else:
                    data['outline'] = {"outline": outline_data}
        
        # æ ‡å‡†åŒ–åˆ†é…æ•°æ®ç»“æ„
        if 'allocation' in data:
            allocation_data = data['allocation']
            # é€‚é…æ–°æ ¼å¼ï¼šoutline_with_allocationsåŒ…å«äº†å®Œæ•´çš„åˆ†é…ä¿¡æ¯
            if "outline_with_allocations" in allocation_data:
                data['allocation'] = allocation_data["outline_with_allocations"]
            
        return data
    
    def _smart_section_match(self, chart_section: str, outline_sections: List[str]) -> str:
        """æ™ºèƒ½åŒ¹é…å›¾è¡¨sectionå’Œå¤§çº²section"""
        import re
        
        # å¤„ç†è¾“å…¥çš„å›¾è¡¨ç« èŠ‚æ ‡è¯†
        chart_section = str(chart_section).strip()
        
        # 1. ç›´æ¥åŒ¹é…ï¼šå¦‚æœchart_sectionå°±æ˜¯"ä¸€"ã€"äºŒ"ç­‰ï¼Œç›´æ¥åŒ¹é…
        if chart_section in ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å"]:
            for outline_section in outline_sections:
                if outline_section.startswith(f"{chart_section}ã€"):
                    return outline_section
        
        # 2. æå–æ•°å­—å‰ç¼€è¿›è¡ŒåŒ¹é…
        def extract_number(section_title):
            match = re.match(r'^([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)ã€', section_title)
            if match:
                chinese_nums = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10}
                return chinese_nums.get(match.group(1), 0)
            return 0
        
        # å¦‚æœchart_sectionæ˜¯æ•°å­—ï¼Œè½¬æ¢ä¸ºå¯¹åº”çš„ä¸­æ–‡æ•°å­—
        try:
            if chart_section.isdigit():
                num = int(chart_section)
                num_to_chinese = {1: 'ä¸€', 2: 'äºŒ', 3: 'ä¸‰', 4: 'å››', 5: 'äº”', 6: 'å…­', 7: 'ä¸ƒ', 8: 'å…«', 9: 'ä¹', 10: 'å'}
                if num in num_to_chinese:
                    target_chinese = num_to_chinese[num]
                    for outline_section in outline_sections:
                        if outline_section.startswith(f"{target_chinese}ã€"):
                            return outline_section
        except:
            pass
        
        chart_num = extract_number(chart_section)
        
        # 3. æ•°å­—å‰ç¼€ç²¾ç¡®åŒ¹é…
        if chart_num > 0:
            for outline_section in outline_sections:
                if extract_number(outline_section) == chart_num:
                    return outline_section
        
        # 4. å…³é”®è¯åŒ¹é…
        chart_keywords = set(re.findall(r'[\u4e00-\u9fff]+', chart_section.replace('ã€', '')))
        
        best_match = None
        best_score = 0
        
        for outline_section in outline_sections:
            outline_keywords = set(re.findall(r'[\u4e00-\u9fff]+', outline_section.replace('ã€', '')))
            # è®¡ç®—äº¤é›†å¾—åˆ†
            intersection = chart_keywords & outline_keywords
            if intersection:
                score = len(intersection) / max(len(chart_keywords), len(outline_keywords))
                if score > best_score:
                    best_score = score
                    best_match = outline_section
        
        # 5. å¦‚æœå…³é”®è¯åŒ¹é…åˆ†æ•°è¶³å¤Ÿé«˜ï¼ˆ>0.2ï¼‰ï¼Œè¿”å›æœ€ä½³åŒ¹é…
        if best_score > 0.2:
            return best_match
            
        return None
    
    def determine_sections_with_data(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        ç¡®å®šå„ç« èŠ‚çš„æ•°æ®åˆ†é…æƒ…å†µï¼ŒåŒ…æ‹¬å›¾è¡¨åˆ†é…
        é€‚é…æ–°çš„æ•°æ®ç»“æ„
        """
        print("ğŸ“‹ è§£æç« èŠ‚æ•°æ®åˆ†é…æƒ…å†µ...")
        
        # ä»ç»Ÿä¸€æ•°æ®ç»“æ„ä¸­æå–ä¿¡æ¯
        outline_data = data.get('outline', {})
        allocation_result = data.get('allocation', {})
        visualization_results = data.get('visualizations', {})
        
        sections_with_data = []
        
        # é€‚é…æ–°çš„æ•°æ®ç»“æ„
        if "reportOutline" in outline_data:
            outline = outline_data["reportOutline"]
        elif "outline" in outline_data:
            outline = outline_data["outline"]
        else:
            outline = outline_data.get("reportOutline", outline_data.get("outline", []))
        
        # å¤„ç†åˆ†é…ç»“æœ - é€‚é…æ–°çš„æ•°æ®ç»“æ„
        if "reportOutline" in allocation_result:
            # æ–°æ ¼å¼ï¼šåˆ†é…ä¿¡æ¯ç›´æ¥åµŒå…¥åœ¨outlineä¸­
            allocated_outline = allocation_result["reportOutline"]
            allocated_sections = {}
            for section in allocated_outline:
                title = section.get("title", "")
                allocated_data_ids = section.get("allocated_data_ids", [])
                allocated_sections[title] = allocated_data_ids
        else:
            # æ—§æ ¼å¼å…¼å®¹
            allocated_sections = allocation_result.get("allocated_sections", {})
            
            if not allocated_sections and isinstance(allocation_result, list):
                # å¦‚æœallocation_resultæ˜¯åˆ—è¡¨æ ¼å¼ï¼Œéœ€è¦è½¬æ¢
                for item in allocation_result:
                    if isinstance(item, dict) and "title" in item:
                        title = item["title"]
                        allocated_data_ids = item.get("allocated_data_ids", [])
                        allocated_sections[title] = allocated_data_ids
        
        # è§£æå›¾è¡¨åˆ†é…ç»“æœ
        chart_allocation = {}
        if visualization_results and "processed_suggestions" in visualization_results:
            print("   ğŸ“Š å¤„ç†å¯è§†åŒ–å›¾è¡¨åˆ†é…...")
            processed_suggestions = visualization_results.get("processed_suggestions", [])
            
            # å»ºç«‹æ™ºèƒ½åŒ¹é…æ˜ å°„
            outline_sections = [section.get("title", "") for section in outline]
            
            for suggestion in processed_suggestions:
                if suggestion.get("success") and suggestion.get("has_png"):
                    section = suggestion.get("section", "")
                    if section:
                        # æ™ºèƒ½åŒ¹é…ï¼šæ‰¾åˆ°æœ€åŒ¹é…çš„å¤§çº²section
                        matched_section = self._smart_section_match(section, outline_sections)
                        if matched_section:
                            if matched_section not in chart_allocation:
                                chart_allocation[matched_section] = []
                            
                            # æ„å»ºå›¾è¡¨ä¿¡æ¯
                            chart_info = {
                                "chart_title": suggestion.get("chart_title", ""),
                                "chart_type": suggestion.get("chart_type", ""),
                                "image_description": suggestion.get("image_description", ""),
                                "png_path": suggestion.get("png_path", ""),
                                "section": section,
                                "priority": suggestion.get("priority", "medium"),
                                "reason": suggestion.get("reason", ""),
                                "asset_id": suggestion.get("asset_id", ""),
                                "file_size": suggestion.get("file_size", 0),
                                "status": "success",
                                "data_source_ids": suggestion.get("data_source_ids", []),
                                "timestamp": suggestion.get("timestamp", "")
                            }
                            chart_allocation[matched_section].append(chart_info)
        
        for i, section in enumerate(outline):
            section_title = section.get("title", "")
            section_points = section.get("points", [])
            
            # è·å–åˆ†é…çš„æ•°æ®ID
            allocated_data_ids = allocated_sections.get(section_title, [])
            
            # è·å–åˆ†é…çš„å›¾è¡¨
            allocated_charts = chart_allocation.get(section_title, [])
            
            section_info = {
                "index": i + 1,
                "title": section_title,
                "points": section_points,
                "allocated_data_ids": allocated_data_ids,
                "allocated_charts": allocated_charts,
                "has_data": len(allocated_data_ids) > 0,
                "has_charts": len(allocated_charts) > 0
            }
            
            sections_with_data.append(section_info)
            
            print(f"   ğŸ“„ {section_title}: {len(allocated_data_ids)}æ•°æ® + {len(allocated_charts)}å›¾è¡¨")
        
        total_data = sum(len(s["allocated_data_ids"]) for s in sections_with_data)
        total_charts = sum(len(s["allocated_charts"]) for s in sections_with_data)
        print(f"âœ… ç« èŠ‚è§£æå®Œæˆ: å…±{len(sections_with_data)}ç« èŠ‚, {total_data}æ•°æ®é¡¹, {total_charts}å›¾è¡¨")
        
        return sections_with_data


# ====================
# åŸºç¡€å†…å®¹ç»„è£…å™¨
# ====================

class ReportContentAssembler:
    """ç»Ÿä¸€çš„æŠ¥å‘Šå†…å®¹ç»„è£…å™¨"""
    
    def __init__(self):
        # å…¨å±€å‚è€ƒæ–‡çŒ®ç®¡ç†
        self.global_references = []  # å­˜å‚¨æ‰€æœ‰å‚è€ƒæ–‡çŒ®
        self.global_id_to_ref = {}   # æ•°æ®IDåˆ°å‚è€ƒæ–‡çŒ®åºå·çš„æ˜ å°„
    
    def reset_references(self):
        """é‡ç½®å‚è€ƒæ–‡çŒ®çŠ¶æ€ï¼ˆç”¨äºç”Ÿæˆæ–°æŠ¥å‘Šæ—¶ï¼‰"""
        self.global_references = []
        self.global_id_to_ref = {}
    
    def update_global_references(self, data_items: List[Dict[str, Any]]) -> None:
        """æ›´æ–°å…¨å±€å‚è€ƒæ–‡çŒ®æ˜ å°„ï¼Œé€‚é…æ–°çš„æ•°æ®ç»“æ„"""
        for data_item in data_items:
            data_id = data_item.get("id")
            # æ„å»ºsource_infoï¼Œé€‚é…æ–°çš„æ•°æ®ç»“æ„
            source_info = {
                "title": data_item.get("title", "æ— æ ‡é¢˜"),
                "url": data_item.get("url", ""),
                "data_source_type": data_item.get("data_source_type", ""),
                "search_query": data_item.get("search_query", "")
            }
            
            if data_id and data_id not in self.global_id_to_ref:
                self.global_references.append(source_info)
                self.global_id_to_ref[data_id] = len(self.global_references)
    
    def convert_data_ids_to_references(self, content: str) -> str:
        """å°†æ•°æ®IDè½¬æ¢ä¸ºå‚è€ƒæ–‡çŒ®åºå·"""
        for data_id, ref_num in self.global_id_to_ref.items():
            content = content.replace(f"[{data_id}]", f"[{ref_num}]")
        return content
    
    def build_chart_content(self, allocated_charts: List[Dict[str, Any]]) -> str:
        """æ„å»ºå›¾è¡¨å†…å®¹å­—ç¬¦ä¸²ï¼ŒåŒ…å«å®Œæ•´çš„å›¾è¡¨ä¿¡æ¯ä¾›LLMè¿›è¡Œå›¾è¡¨å¢å¼ºï¼Œå¹¶ç»™å‡ºmarkdownç»å¯¹è·¯å¾„å›¾ç‰‡å¼•ç”¨ç¤ºä¾‹"""
        if not allocated_charts:
            return "æœ¬ç« èŠ‚æš‚æ— å¯ç”¨å›¾è¡¨ã€‚"
        
        chart_content = "### å¯ç”¨å›¾è¡¨èµ„æº:\n\n"
        for i, chart in enumerate(allocated_charts, 1):
            # å…¼å®¹æ–°æ—§æ ¼å¼çš„å­—æ®µæ˜ å°„
            title = (chart.get("chart_title", "") or 
                    chart.get("title", "") or 
                    f"å›¾è¡¨{i}")
            
            description = (chart.get("image_description", "") or 
                          chart.get("description", "") or 
                          "æ— æè¿°")
            
            chart_type = (chart.get("chart_type", "") or 
                         chart.get("visualization_type", "") or 
                         "æœªçŸ¥ç±»å‹")
            
            png_path = (chart.get("png_path", "") or 
                       chart.get("chart_png_path", "") or 
                       "")
            
            chart_html = chart.get("chart_html", "")
            priority = chart.get("priority", "")
            reason = chart.get("reason", "")
            asset_id = chart.get("asset_id", "")
            data_source = chart.get("data_source", "")
            
            chart_content += f"**å›¾{i}: {title}**\n"
            chart_content += f"- å›¾è¡¨ç±»å‹: {chart_type}\n"
            chart_content += f"- å›¾ç‰‡ç»å¯¹è·¯å¾„: {png_path}\n"
            chart_content += f"- **Markdownå›¾ç‰‡å¼•ç”¨**: ![]({png_path})\n"
            
            if priority:
                chart_content += f"- ä¼˜å…ˆçº§: {priority}\n"
            if reason:
                chart_content += f"- åˆ†æä»·å€¼: {reason}\n"
            if asset_id:
                chart_content += f"- èµ„äº§ID: {asset_id}\n"
            if data_source:
                chart_content += f"- æ•°æ®æ¥æº: {data_source}\n"
            
            # é‡è¦ï¼šæ·»åŠ è¯¦ç»†çš„å›¾è¡¨æè¿°
            if description and description != "æ— æè¿°":
                chart_content += f"- **è¯¦ç»†æè¿°**: {description}\n"
            
            # å¦‚æœæœ‰HTMLä»£ç ï¼Œä¹Ÿæä¾›ç»™LLMå‚è€ƒ
            if chart_html:
                chart_content += f"- **å›¾è¡¨HTMLä»£ç **: \n```html\n{chart_html[:500]}{'...(ä»£ç è¿‡é•¿å·²æˆªæ–­)' if len(chart_html) > 500 else ''}\n```\n"
                
            chart_content += "\n"
        
        chart_content += "**å›¾è¡¨å¼•ç”¨è¯´æ˜**: \n"
        chart_content += "1. åœ¨åˆ†æä¸­å¼•ç”¨å›¾è¡¨æ—¶ï¼Œè¯·ä½¿ç”¨markdownè¯­æ³• ![](ç»å¯¹è·¯å¾„) æ’å…¥å›¾ç‰‡ï¼Œç»å¯¹è·¯å¾„è§ä¸Šæ–¹ã€‚\n"
        chart_content += "2. è¯·ç»“åˆå›¾è¡¨çš„è¯¦ç»†æè¿°è¿›è¡Œæ·±å…¥åˆ†æï¼Œä¸è¦ç®€å•é‡å¤æè¿°å†…å®¹ã€‚\n"
        chart_content += "3. é‡ç‚¹è§£è¯»å›¾è¡¨ä¸­çš„æ•°æ®è¶‹åŠ¿ã€å¯¹æ¯”ç»“æœå’Œä¸šåŠ¡å«ä¹‰ã€‚\n"
        chart_content += "4. å°†å›¾è¡¨åˆ†æä¸ç« èŠ‚ä¸»é¢˜ç´§å¯†ç»“åˆï¼Œæä¾›æœ‰ä»·å€¼çš„æ´å¯Ÿã€‚\n\n"
        
        return chart_content
    
    def build_data_content(self, collected_data_info: Dict[str, Any], processing_method: str) -> str:
        """æ„å»ºæ•°æ®å†…å®¹å­—ç¬¦ä¸²"""
        data_content = ""
        
        if processing_method == "summarized":
            summary = collected_data_info.get("summary", "")
            data_content = f"### æ•°æ®æ‘˜è¦:\n\n{summary}\n\n"
        elif processing_method == "full_data":
            for data_item in collected_data_info.get("collected_data", []):
                content = data_item.get("content", "")
                data_id = data_item.get("id")
                
                if content and data_id:
                    ref_num = self.global_id_to_ref.get(data_id, data_id)
                    data_content += f"**æ•°æ®æ¥æº[{ref_num}]**: {content}\n\n"
        elif processing_method == "selected_data":
            for data_item in collected_data_info.get("collected_data", []):
                content = data_item.get("content", "")
                data_id = data_item.get("id")
                
                if content and data_id:
                    ref_num = self.global_id_to_ref.get(data_id, data_id)
                    data_content += f"**å…³é”®æ•°æ®[{ref_num}]**: {content}\n\n"
        
        if not data_content:
            data_content = "æœ¬ç« èŠ‚æš‚æ— ç›¸å…³æ•°æ®æ”¯æ’‘ã€‚\n\n"
        
        return data_content
    
    def get_report_title(self, subject_name: str, report_type: str = "ç ”ç©¶æŠ¥å‘Š") -> str:
        """è·å–æŠ¥å‘Šæ ‡é¢˜"""
        return f"{subject_name}{report_type}"
    
    def assemble_final_report(
        self,
        subject_name: str,
        report_plan: Dict[str, Any],
        generated_sections: List[Dict[str, Any]],
        report_type: str = "ç ”ç©¶æŠ¥å‘Š"
    ) -> Dict[str, Any]:
        """ç»„è£…æœ€ç»ˆæŠ¥å‘Š"""
        report_title = self.get_report_title(subject_name, report_type)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_sections = len(generated_sections)
        sections_with_data = len([s for s in generated_sections if s.get("generation_method") != "no_data"])
        total_charts = sum(len(s.get("allocated_charts", [])) for s in generated_sections)
        
        final_report = {
            "report_title": report_title,
            "subject_name": subject_name,
            "report_plan": report_plan,
            "sections": generated_sections,
            "references": self.global_references,
            "generation_stats": {
                "total_sections": total_sections,
                "sections_with_data": sections_with_data,
                "sections_without_data": total_sections - sections_with_data,
                "total_charts": total_charts
            }
        }
        
        # ç”Ÿæˆmarkdownå†…å®¹
        final_report["content"] = self.assemble_markdown_report(final_report)
        
        return final_report
    
    def assemble_markdown_report(self, final_report: dict) -> str:
        """å°†æœ€ç»ˆæŠ¥å‘Šè½¬æ¢ä¸ºMarkdownæ ¼å¼"""
        lines = []
        subject_name = final_report.get("subject_name", "ç ”ç©¶ä¸»ä½“")
        report_title = final_report.get("report_title", f"{subject_name}ç ”ç©¶æŠ¥å‘Š")
        sections = final_report.get("sections", [])
        references = final_report.get("references", [])
        
        # æŠ¥å‘Šæ ‡é¢˜
        lines.append(f"# {report_title}\n")
        
        # ç›®å½•
        lines.append("## ç›®å½•\n")
        for i, section in enumerate(sections, 1):
            title = section.get("section_title", f"ç« èŠ‚{i}")
            # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦å·²ç»åŒ…å«ä¸­æ–‡åºå·
            if any(num in title for num in ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å']):
                lines.append(f"{title}")
            else:
                lines.append(f"{i}. {title}")
        lines.append("")
        
        # ç« èŠ‚å†…å®¹
        for i, section in enumerate(sections, 1):
            title = section.get("section_title", f"ç« èŠ‚{i}")
            content = section.get("content", "")
            
            # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦å·²ç»åŒ…å«ä¸­æ–‡åºå·
            if any(num in title for num in ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å']):
                lines.append(f"## {title}\n")
            else:
                lines.append(f"## {i}. {title}\n")
            
            lines.append(content)
            lines.append("\n")
        
        # å‚è€ƒæ–‡çŒ®
        if references:
            lines.append("## å‚è€ƒæ–‡çŒ®\n")
            for i, ref in enumerate(references, 1):
                title = ref.get("title", "æ— æ ‡é¢˜")
                url = ref.get("url", "")
                if url:
                    lines.append(f"[{i}] {title} - {url}")
                else:
                    lines.append(f"[{i}] {title}")
            lines.append("")
        
        return "\n".join(lines)


# ====================
# ç»Ÿä¸€æŠ¥å‘Šç”Ÿæˆå™¨
# ====================

class UnifiedReportGenerator:
    """ç»Ÿä¸€çš„æŠ¥å‘Šç”Ÿæˆå™¨ï¼Œæ”¯æŒå…¬å¸ã€è¡Œä¸šã€å®è§‚æŠ¥å‘Š"""
    
    def __init__(
        self,
        api_key: str,
        base_url: str,
        model: str,
        report_type: str = "company",  # company, industry, macro
        max_context_tokens: int = 128 * 1024,
        context_usage_ratio: float = 0.8
    ):
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.report_type = report_type
        self.max_context_tokens = max_context_tokens
        self.available_tokens = int(max_context_tokens * context_usage_ratio)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()
        self._setup_prompts()
    
    def _initialize_components(self):
        """åˆå§‹åŒ–å„ä¸ªç»„ä»¶"""
        self.token_calculator = TransformerTokenCalculator(model_name="deepseek-ai/DeepSeek-V3-0324")
        self.data_processor = ReportDataProcessor()
        self.content_assembler = ReportContentAssembler()
    
    def _setup_prompts(self):
        """æ ¹æ®æŠ¥å‘Šç±»å‹è®¾ç½®æç¤ºè¯"""
        if self.report_type == "company":
            self.section_with_data_prompt = COMPANY_SECTION_WITH_DATA_PROMPT
            self.section_without_data_prompt = COMPANY_SECTION_WITHOUT_DATA_PROMPT
            self.chart_enhancement_prompt = SECTION_CHART_ENHANCEMENT_PROMPT
        elif self.report_type == "industry":
            self.section_with_data_prompt = INDUSTRY_SECTION_WITH_DATA_PROMPT
            self.section_without_data_prompt = INDUSTRY_SECTION_WITHOUT_DATA_PROMPT
            self.chart_enhancement_prompt = SECTION_CHART_ENHANCEMENT_PROMPT
        elif self.report_type == "macro":
            self.section_with_data_prompt = MACRO_SECTION_WITH_DATA_PROMPT
            self.section_without_data_prompt = MACRO_SECTION_WITHOUT_DATA_PROMPT
            self.chart_enhancement_prompt = SECTION_CHART_ENHANCEMENT_PROMPT
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æŠ¥å‘Šç±»å‹: {self.report_type}")
    
    @classmethod
    def from_env(cls, report_type: str = "company", context_usage_ratio: float = 0.8):
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨"""
        load_dotenv()
        
        # ä½¿ç”¨é€šç”¨APIé…ç½®ï¼ˆç¡…åŸºæµåŠ¨ç­‰ï¼‰ï¼Œä¸base_data_collectionä¿æŒä¸€è‡´
        api_key = os.getenv("GUIJI_API_KEY")
        base_url = os.getenv("GUIJI_BASE_URL") 
        model = os.getenv("GUIJI_TEXT_MODEL_DEEPSEEK_PRO")
        max_context_tokens = int(128 * 1024 * context_usage_ratio)
        
        if not all([api_key, base_url, model]):
            raise ValueError("ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: GUIJI_API_KEY, GUIJI_BASE_URL, GUIJI_TEXT_MODEL_DEEPSEEK_PRO")
        
        return cls(
            api_key=api_key,
            base_url=base_url,
            model=model,
            report_type=report_type,
            max_context_tokens=max_context_tokens,
            context_usage_ratio=1.0
        )
    
    def load_report_data(self, **kwargs) -> Dict[str, Any]:
        """åŠ è½½æŠ¥å‘Šæ•°æ®"""
        return self.data_processor.load_report_data(**kwargs)
    
    def generate_complete_report(
        self,
        subject_name: str,
        data: Dict[str, Any],
        output_file: str = None,
        enable_chart_enhancement: bool = True
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´çš„ç ”ç©¶æŠ¥å‘Š
        
        Args:
            subject_name: ç ”ç©¶ä¸»ä½“åç§°
            data: ç»Ÿä¸€æ•°æ®ç»“æ„ï¼ˆåŒ…å«æ‰€æœ‰å¿…è¦æ•°æ®ï¼‰
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            enable_chart_enhancement: æ˜¯å¦å¯ç”¨å›¾è¡¨å¢å¼ºï¼ˆé»˜è®¤Trueï¼‰
        """
        print(f"\nğŸ“ å¼€å§‹ç”Ÿæˆ {subject_name} {self.report_type} ç ”ç©¶æŠ¥å‘Š...")
        
        # é‡ç½®å‚è€ƒæ–‡çŒ®çŠ¶æ€
        self.content_assembler.reset_references()
        
        # 1. è§£æå¤§çº²å’Œæ•°æ®åˆ†é…
        sections_with_data = self.data_processor.determine_sections_with_data(data)
        print(f"ğŸ“‹ æŠ¥å‘ŠåŒ…å« {len(sections_with_data)} ä¸ªç« èŠ‚")
        
        # 2. åˆ›å»ºç®€å•çš„æŠ¥å‘Šä¸Šä¸‹æ–‡
        report_context = {
            "subject_name": subject_name,
            "total_sections": len(sections_with_data)
        }
        
        # 3. æå–æ‰å¹³åŒ–æ•°æ®
        all_flattened_data = data.get('flattened_data', [])
        visualization_results = data.get('visualizations', {})
        
        # 4. ç”Ÿæˆç« èŠ‚å†…å®¹ï¼ˆåŒ…å«å¢é‡å¼æ•°æ®å¤„ç†å’Œç«‹å³å›¾è¡¨å¢å¼ºï¼‰
        print(f"\nğŸ”„ ç”Ÿæˆç« èŠ‚å†…å®¹ï¼ˆæ•°æ®+å›¾è¡¨å¢å¼ºï¼‰...")
        generated_sections = []
        for i, section_info in enumerate(sections_with_data):
            print(f"\nğŸ“ ç”Ÿæˆç¬¬ {i+1}/{len(sections_with_data)} ç« èŠ‚: {section_info['title']}")
            
            section_content = self._generate_section_content_base(
                section_info=section_info,
                subject_name=subject_name,
                all_data=all_flattened_data,
                report_context=report_context,
                enable_chart_enhancement=enable_chart_enhancement
            )
            
            generated_sections.append(section_content)
            print(f"âœ… ç« èŠ‚ '{section_info['title']}' ç”Ÿæˆå®Œæˆ")
        
        # 5. è·³è¿‡ç¬¬äºŒè½®å¢å¼ºï¼ˆå› ä¸ºå·²ç»åœ¨ç¬¬4æ­¥ä¸­å®Œæˆäº†ï¼‰
        print(f"\nâœ… æ‰€æœ‰ç« èŠ‚å·²å®Œæˆå¢é‡å¼ç”Ÿæˆå’Œå›¾è¡¨å¢å¼º")
        
        # 6. ç»„è£…å®Œæ•´æŠ¥å‘Š
        final_report = self.content_assembler.assemble_final_report(
            subject_name=subject_name,
            report_plan=report_context,
            generated_sections=generated_sections,
            report_type=f"{self.report_type}ç ”ç©¶æŠ¥å‘Š"
        )
        
        # 7. ä¿å­˜æŠ¥å‘Š
        if output_file:
            if output_file.lower().endswith(".md"):
                with open(output_file, "w", encoding="utf-8") as f:
                    f.write(final_report["content"])
                print(f"ğŸ“ Markdown æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
            else:
                with open(output_file, "w", encoding="utf-8") as f:
                    json.dump(final_report, f, ensure_ascii=False, indent=2)
                print(f"ï¿½ JSON æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        
        # 8. ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = {
            "total_sections": len(generated_sections),
            "sections_with_data": sum(1 for s in sections_with_data if s["has_data"]),
            "sections_without_data": sum(1 for s in sections_with_data if not s["has_data"]), 
            "total_charts": sum(len(s.get("allocated_charts", [])) for s in sections_with_data)
        }
        
        print(f"ğŸ‰ {subject_name} {self.report_type} ç ”ç©¶æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        return final_report
    
    def _generate_section_content_base(
        self,
        section_info: Dict[str, Any],
        subject_name: str,
        all_data: List[Dict[str, Any]],
        report_context: Dict[str, Any],
        enable_chart_enhancement: bool = True
    ) -> Dict[str, Any]:
        """ç”Ÿæˆç« èŠ‚å†…å®¹ï¼šå…ˆåŸºç¡€å†…å®¹ï¼Œç„¶åç«‹å³æ£€æŸ¥å›¾è¡¨å¢å¼º"""
        section_title = section_info["title"]
        section_points = section_info["points"]
        allocated_data_ids = section_info["allocated_data_ids"]
        allocated_charts = section_info.get("allocated_charts", [])
        
        print(f"   ğŸ“Š å‡†å¤‡ç« èŠ‚æ•°æ®...")
        
        # 1. ç›´æ¥è·å–åˆ†é…ç»™æ­¤ç« èŠ‚çš„æ•°æ®
        allocated_data_info = self._get_allocated_data_direct(
            allocated_data_ids=allocated_data_ids,
            all_data=all_data
        )
        
        # 2. ç”ŸæˆåŸºç¡€å†…å®¹ï¼ˆä¸åŒ…å«å›¾è¡¨ï¼‰
        if not allocated_data_info["has_data"]:
            print(f"   âš ï¸  æ— æ•°æ®æ”¯æ’‘ï¼Œç”ŸæˆåŸºç¡€æ¡†æ¶")
            base_content = self._generate_section_without_data(section_info, subject_name)
        else:
            print(f"   ğŸ“ åŸºäºåˆ†é…æ•°æ®ç”Ÿæˆå†…å®¹ (æ•°æ®æ¡æ•°: {len(allocated_data_info['data_items'])})")
            base_content = self._generate_section_with_data_incremental(
                section_info=section_info,
                allocated_data_info=allocated_data_info,
                subject_name=subject_name,
                report_context=report_context
            )
        
        # 3. ç«‹å³æ£€æŸ¥æ˜¯å¦æœ‰å›¾è¡¨ï¼Œå¦‚æœæœ‰åˆ™è¿›è¡Œå›¾è¡¨å¢å¼º
        final_content = base_content
        has_chart_enhancement = False
        
        if enable_chart_enhancement and len(allocated_charts) > 0:
            print(f"   ğŸ¨ å‘ç° {len(allocated_charts)} ä¸ªå›¾è¡¨ï¼Œç«‹å³è¿›è¡Œå›¾è¡¨å¢å¼º...")
            
            # æ„å»ºå›¾è¡¨å†…å®¹
            chart_content = self.content_assembler.build_chart_content(allocated_charts)
            
            # ä½¿ç”¨å›¾è¡¨å¢å¼ºæç¤ºè¯
            enhancement_prompt = self.chart_enhancement_prompt.format(
                original_content=base_content,
                chart_content=chart_content
            )
            
            try:
                enhanced_content = chat_no_tool(
                    user_content=enhancement_prompt,
                    system_content="",
                    api_key=self.api_key,
                    base_url=self.base_url,
                    model=self.model,
                    temperature=0.3,
                    max_tokens=8192
                )
                
                final_content = enhanced_content.strip()
                has_chart_enhancement = True
                print(f"     âœ… å›¾è¡¨å¢å¼ºå®Œæˆ")
                
            except Exception as e:
                print(f"     âš ï¸ å›¾è¡¨å¢å¼ºå¤±è´¥ï¼Œä¿ç•™åŸºç¡€å†…å®¹: {e}")
                has_chart_enhancement = False
        else:
            print(f"   â­ï¸  æ— å›¾è¡¨æˆ–ç¦ç”¨å›¾è¡¨å¢å¼ºï¼Œè·³è¿‡å¢å¼ºæ­¥éª¤")
        
        return {
            "section_index": section_info["index"],
            "section_title": section_title,
            "section_points": section_points,
            "content": final_content,
            "data_info": allocated_data_info,
            "allocated_charts": allocated_charts,
            "charts_count": len(allocated_charts),
            "generation_method": "incremental" if allocated_data_info["has_data"] else "no_data",
            "has_chart_enhancement": has_chart_enhancement  # æ ‡è®°æ˜¯å¦å·²è¿›è¡Œå›¾è¡¨å¢å¼º
        }

    def _get_allocated_data_direct(
        self,
        allocated_data_ids: List[str],
        all_data: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ç›´æ¥è·å–åˆ†é…ç»™ç« èŠ‚çš„æ•°æ®ï¼Œä¸è¿›è¡Œæ€»ç»“ï¼Œé€‚é…æ–°çš„æ•°æ®ç»“æ„"""
        if not allocated_data_ids:
            return {
                "has_data": False,
                "data_items": [],
                "total_data_count": 0
            }
        
        # æ ¹æ®IDæŸ¥æ‰¾å¯¹åº”çš„æ•°æ®ï¼Œæ–°æ•°æ®ç»“æ„ä¸­IDæ˜¯å­—ç¬¦ä¸²
        data_items = []
        for data_item in all_data:
            item_id = str(data_item.get("id", ""))
            if item_id in allocated_data_ids:
                data_items.append(data_item)
        
        return {
            "has_data": len(data_items) > 0,
            "data_items": data_items,
            "total_data_count": len(data_items)
        }
    
    def _generate_section_with_data_incremental(
        self,
        section_info: Dict[str, Any],
        allocated_data_info: Dict[str, Any],
        subject_name: str,
        report_context: Dict[str, Any]
    ) -> str:
        """åŸºäºåˆ†é…çš„æ•°æ®è¿›è¡Œå¢é‡å¼å†…å®¹ç”Ÿæˆï¼Œé€‚é…æ–°çš„æ•°æ®ç»“æ„"""
        section_title = section_info["title"]
        points = section_info["points"]
        data_items = allocated_data_info["data_items"]
        
        # æ„å»ºåŸºç¡€æç¤ºè¯
        points_text = "\n".join([f"- {point}" for point in points])
        
        # åˆå§‹åŒ–å†…å®¹
        current_content = ""
        used_token_count = 0
        
        # è®¡ç®—åŸºç¡€æç¤ºè¯çš„tokenæ•°
        base_prompt = self.section_with_data_prompt.format(
            subject_name=subject_name,
            section_title=section_title,
            points_text=points_text,
            data_content=""
        )
        base_tokens = self.token_calculator.count_tokens(base_prompt)
        
        # ä¸ºå½“å‰å†…å®¹å’Œè¾“å‡ºé¢„ç•™token
        content_tokens = self.token_calculator.count_tokens(current_content) if current_content else 0
        output_tokens = 8192  # é¢„ç•™è¾“å‡ºtoken
        available_tokens = self.available_tokens - base_tokens - content_tokens - output_tokens
        
        print(f"      å¯ç”¨tokens: {available_tokens}, æ•°æ®é¡¹: {len(data_items)}")
        
        # æ›´æ–°å…¨å±€å‚è€ƒæ–‡çŒ®
        self.content_assembler.update_global_references(data_items)
        
        # å¢é‡å¼æ·»åŠ æ•°æ®å¹¶ç”Ÿæˆå†…å®¹
        batch_data = []
        batch_tokens = 0
        
        for i, data_item in enumerate(data_items):
            content = data_item.get("content", "")
            data_id = str(data_item.get("id", ""))
            
            if not content:
                continue
            
            # è·å–å‚è€ƒæ–‡çŒ®ç¼–å·
            ref_num = self.content_assembler.global_id_to_ref.get(data_id, data_id)
            formatted_data = f"**æ•°æ®æ¥æº[{ref_num}]**: {content}\n\n"
            data_tokens = self.token_calculator.count_tokens(formatted_data)
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ·»åŠ åˆ°å½“å‰æ‰¹æ¬¡
            if batch_tokens + data_tokens <= available_tokens:
                batch_data.append(formatted_data)
                batch_tokens += data_tokens
            else:
                # å½“å‰æ‰¹æ¬¡å·²æ»¡ï¼Œç”Ÿæˆå†…å®¹
                if batch_data:
                    batch_content = self._generate_content_with_batch(
                        subject_name, section_title, points_text, 
                        "".join(batch_data), current_content
                    )
                    if batch_content:
                        current_content = batch_content
                        # é‡æ–°è®¡ç®—å½“å‰å†…å®¹çš„tokenæ•°
                        content_tokens = self.token_calculator.count_tokens(current_content)
                        available_tokens = self.available_tokens - base_tokens - content_tokens - output_tokens
                        print(f"      å·²ç”Ÿæˆå†…å®¹ï¼Œå‰©ä½™tokens: {available_tokens}")
                
                # å¼€å§‹æ–°æ‰¹æ¬¡
                batch_data = [formatted_data]
                batch_tokens = data_tokens
            
            print(f"      å¤„ç†æ•°æ® {i+1}/{len(data_items)}, æ‰¹æ¬¡tokens: {batch_tokens}")
        
        # å¤„ç†æœ€åä¸€ä¸ªæ‰¹æ¬¡
        if batch_data:
            batch_content = self._generate_content_with_batch(
                subject_name, section_title, points_text, 
                "".join(batch_data), current_content
            )
            if batch_content:
                current_content = batch_content
        
        return current_content if current_content else self._generate_section_without_data(section_info, subject_name)
    
    def _generate_content_with_batch(
        self,
        subject_name: str,
        section_title: str,
        points_text: str,
        batch_data: str,
        current_content: str
    ) -> str:
        """ä½¿ç”¨å½“å‰æ‰¹æ¬¡æ•°æ®ç”Ÿæˆæˆ–å¢å¼ºå†…å®¹"""
        
        if current_content:
            # å¢é‡æ¨¡å¼ï¼šåŸºäºå·²æœ‰å†…å®¹ç»§ç»­æ‰©å±•
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶æŠ¥å‘Šæ’°å†™ä¸“å®¶ã€‚ç°åœ¨éœ€è¦ä½ åŸºäºå·²æœ‰çš„ç« èŠ‚å†…å®¹å’Œæ–°å¢çš„æ•°æ®ï¼Œç»§ç»­å®Œå–„å’Œæ‰©å±•è¿™ä¸ªç« èŠ‚ã€‚

**ç ”ç©¶ä¸»ä½“**: {subject_name}
**ç« èŠ‚æ ‡é¢˜**: {section_title}
**ç« èŠ‚è¦ç‚¹**:
{points_text}

**å·²æœ‰å†…å®¹**:
{current_content}

**æ–°å¢æ•°æ®**:
{batch_data}

**ä»»åŠ¡è¦æ±‚**:
1. åŸºäºæ–°å¢æ•°æ®ï¼Œç»§ç»­å®Œå–„å’Œæ‰©å±•å·²æœ‰å†…å®¹
2. ç¡®ä¿æ–°å†…å®¹ä¸å·²æœ‰å†…å®¹é€»è¾‘è¿è´¯
3. é€‚å½“å¼•ç”¨æ•°æ®æ¥æºï¼Œä½¿ç”¨[æ•°å­—]æ ¼å¼æ ‡æ³¨
4. ä¿æŒä¸“ä¸šçš„åˆ†ææ·±åº¦å’Œå®¢è§‚æ€§
5. ä¸è¦é‡å¤å·²æœ‰å†…å®¹ï¼Œåªå¢åŠ æ–°çš„åˆ†æå’Œè§è§£

è¯·è¾“å‡ºå®Œæ•´çš„ç« èŠ‚å†…å®¹ï¼ˆåŒ…å«å·²æœ‰å†…å®¹çš„æ”¹è¿›ç‰ˆæœ¬ï¼‰:"""
        else:
            # åˆå§‹æ¨¡å¼ï¼šåŸºäºæ•°æ®ç”Ÿæˆå…¨æ–°å†…å®¹
            prompt = self.section_with_data_prompt.format(
                subject_name=subject_name,
                section_title=section_title,
                points_text=points_text,
                data_content=batch_data
            )
        
        try:
            response = chat_no_tool(
                user_content=prompt,
                system_content="",
                api_key=self.api_key,
                base_url=self.base_url,
                model=self.model,
                temperature=0.4,
                max_tokens=8192
            )
            return response.strip()
        except Exception as e:
            print(f"        âŒ å†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
            return current_content  # è¿”å›å·²æœ‰å†…å®¹

    def _enhance_sections_with_charts(
        self,
        generated_sections: List[Dict[str, Any]],
        subject_name: str
    ) -> List[Dict[str, Any]]:
        """ç¬¬äºŒè½®å¢å¼ºï¼šå¯¹æœ‰å›¾è¡¨çš„ç« èŠ‚è¿›è¡Œå›¾è¡¨å¢å¼º"""
        enhanced_sections = []
        
        for section in generated_sections:
            allocated_charts = section.get("allocated_charts", [])
            
            if len(allocated_charts) > 0:
                print(f"   ğŸ¨ å¢å¼ºç« èŠ‚ '{section['section_title']}' ({len(allocated_charts)}ä¸ªå›¾è¡¨)")
                
                # æ„å»ºå›¾è¡¨å†…å®¹
                chart_content = self.content_assembler.build_chart_content(allocated_charts)
                
                # ä½¿ç”¨å›¾è¡¨å¢å¼ºæç¤ºè¯
                enhancement_prompt = self.chart_enhancement_prompt.format(
                    original_content=section["content"],
                    chart_content=chart_content
                )
                
                try:
                    enhanced_content = chat_no_tool(
                        user_content=enhancement_prompt,
                        system_content="",
                        api_key=self.api_key,
                        base_url=self.base_url,
                        model=self.model,
                        temperature=0.3,
                        max_tokens=8192
                    )
                    
                    # æ›´æ–°ç« èŠ‚å†…å®¹
                    section["content"] = enhanced_content.strip()
                    section["has_chart_enhancement"] = True
                    print(f"     âœ… å›¾è¡¨å¢å¼ºå®Œæˆ")
                    
                except Exception as e:
                    print(f"     âš ï¸ å›¾è¡¨å¢å¼ºå¤±è´¥ï¼Œä¿ç•™åŸå†…å®¹: {e}")
                    section["has_chart_enhancement"] = False
            else:
                print(f"   â­ï¸  ç« èŠ‚ '{section['section_title']}' æ— å›¾è¡¨ï¼Œè·³è¿‡å¢å¼º")
                section["has_chart_enhancement"] = False
            
            enhanced_sections.append(section)
        
        return enhanced_sections
    
    def _generate_section_without_data(self, section_info: Dict[str, Any], subject_name: str) -> str:
        """ä¸ºæ— æ•°æ®æ”¯æ’‘çš„ç« èŠ‚ç”ŸæˆåŸºç¡€æ¡†æ¶"""
        section_title = section_info["title"]
        points = section_info["points"]
        
        points_text = "\n".join([f"- {point}" for point in points])
        
        prompt = self.section_without_data_prompt.format(
            subject_name=subject_name,
            section_title=section_title,
            points_text=points_text
        )

        try:
            response = chat_no_tool(
                user_content=prompt,
                api_key=self.api_key,
                base_url=self.base_url,
                model=self.model,
                temperature=0.5,
                max_tokens=1024
            )
            return response.strip()
        except Exception as e:
            print(f"     âŒ ç« èŠ‚æ¡†æ¶ç”Ÿæˆå¤±è´¥: {e}")
            return f"""æœ¬ç« èŠ‚æ—¨åœ¨åˆ†æ{subject_name}åœ¨{section_title}æ–¹é¢çš„è¡¨ç°ã€‚ä¸»è¦å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼š

{points_text}

*æ³¨ï¼šæœ¬ç« èŠ‚éœ€è¦è¿›ä¸€æ­¥æ”¶é›†ç›¸å…³æ•°æ®ä»¥æä¾›è¯¦ç»†åˆ†æã€‚*"""


# ====================
# ä¾¿æ·åˆ›å»ºå‡½æ•°
# ====================

def create_company_generator(**kwargs) -> UnifiedReportGenerator:
    """åˆ›å»ºå…¬å¸æŠ¥å‘Šç”Ÿæˆå™¨"""
    return UnifiedReportGenerator(report_type="company", **kwargs)

def create_industry_generator(**kwargs) -> UnifiedReportGenerator:
    """åˆ›å»ºè¡Œä¸šæŠ¥å‘Šç”Ÿæˆå™¨"""
    return UnifiedReportGenerator(report_type="industry", **kwargs)

def create_macro_generator(**kwargs) -> UnifiedReportGenerator:
    """åˆ›å»ºå®è§‚æŠ¥å‘Šç”Ÿæˆå™¨"""
    return UnifiedReportGenerator(report_type="macro", **kwargs)


# ====================
# ä¸»ç¨‹åºç¤ºä¾‹
# ====================

if __name__ == "__main__":
    """ä¸»ç¨‹åºå…¥å£ - ç”Ÿæˆè¡Œä¸šç ”ç©¶æŠ¥å‘Šç¤ºä¾‹"""
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # è¡Œä¸šæŠ¥å‘Šé…ç½®
    industry_name = "ä¸­å›½æ™ºèƒ½æœåŠ¡æœºå™¨äººäº§ä¸š"
    data_directory = "test_industry_datas"
    images_directory = "test_industry_datas/images"
    output_file = "test_industry_datas/generated_industry_report_unified.md"
    
    try:
        print("ğŸ“‚ åŠ è½½è¡Œä¸šæ•°æ®æ–‡ä»¶...")
        
        # åˆ›å»ºè¡Œä¸šæŠ¥å‘Šç”Ÿæˆå™¨
        generator = UnifiedReportGenerator.from_env(report_type="industry")
        
        # åŠ è½½æ•°æ® - ä½¿ç”¨æ–°çš„ç»Ÿä¸€æ¥å£
        data = generator.load_report_data(
            data_dir=data_directory,
            images_directory=images_directory
        )
        print("âœ… è¡Œä¸šæ•°æ®åŠ è½½å®Œæˆ")
        
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {industry_name} è¡Œä¸šç ”ç©¶æŠ¥å‘Š...")
        
        # ç”ŸæˆæŠ¥å‘Š - ä½¿ç”¨æ–°çš„ç»Ÿä¸€æ¥å£
        report = generator.generate_complete_report(
            subject_name=industry_name,
            data=data,
            output_file=output_file
        )
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š è¡Œä¸šæŠ¥å‘Šç”Ÿæˆç»Ÿè®¡:")
        stats = report.get("generation_stats", {})
        print(f"   - æ€»ç« èŠ‚æ•°: {stats.get('total_sections', 0)}")
        print(f"   - æœ‰æ•°æ®æ”¯æ’‘: {stats.get('sections_with_data', 0)}")
        print(f"   - æ— æ•°æ®æ”¯æ’‘: {stats.get('sections_without_data', 0)}")
        print(f"   - æ€»å›¾è¡¨æ•°: {stats.get('total_charts', 0)}")
        
        print(f"\nğŸ‰ {industry_name} è¡Œä¸šç ”ç©¶æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“ æŠ¥å‘Šæ–‡ä»¶: {output_file}")
        
    except Exception as e:
        print(f"âŒ è¡Œä¸šæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        traceback.print_exc()
