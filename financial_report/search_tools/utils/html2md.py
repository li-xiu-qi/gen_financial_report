import requests
import trafilatura
from markdownify import markdownify as md
import json
from dateutil.parser import parse
from datetime import timezone
from typing import Optional
import asyncio
from bs4 import BeautifulSoup
from markdownify import MarkdownConverter
import re
from typing import List, Dict, Any
from markdownify import MarkdownConverter, abstract_inline_conversion, chomp
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
import asyncio
import os
from typing import Optional


class ImageDescMarkdownConverter(MarkdownConverter):
    """
    è‡ªå®šä¹‰Markdownè½¬æ¢å™¨ï¼Œç»§æ‰¿è‡ªMarkdownConverterã€‚
    æä¾›äº†æ›´çµæ´»çš„HTMLåˆ°Markdownè½¬æ¢é€‰é¡¹ï¼Œä¾‹å¦‚ï¼š
    - è½¬æ¢é“¾æ¥ä¸ºç»å¯¹è·¯å¾„ã€‚
    - ç§»é™¤æ‰€æœ‰é“¾æ¥å’Œå›¾ç‰‡ã€‚
    - ç‰¹æ®Šå¤„ç†åŒ…å«colspanæˆ–rowspançš„è¡¨æ ¼ã€‚
    """

    def __init__(self, **kwargs):
        """
        åˆå§‹åŒ–è‡ªå®šä¹‰çš„Markdownè½¬æ¢å™¨ã€‚

        :param current_url: å½“å‰é¡µé¢çš„URLï¼Œç”¨äºå°†ç›¸å¯¹é“¾æ¥å’Œå›¾ç‰‡è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ã€‚
                            å¦‚æœæä¾›äº†æ­¤å‚æ•°ï¼Œå›¾ç‰‡å’Œé“¾æ¥çš„URLå°†è‡ªåŠ¨è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ã€‚
        :param kwargs: å…¶ä»–ä¼ é€’ç»™çˆ¶ç±»MarkdownConverterçš„å‚æ•°ã€‚
                       ä¾‹å¦‚ï¼šstrip (éœ€è¦ç§»é™¤çš„æ ‡ç­¾åˆ—è¡¨), convert (ä»…è½¬æ¢çš„æ ‡ç­¾åˆ—è¡¨), heading_styleç­‰ã€‚
        """
        super().__init__(**kwargs)
        self.current_url = kwargs.get("current_url", None)
        self.img_desc_map = kwargs.get("img_desc_map", {})

    def convert_img(self, el, text, parent_tags):
        """
        è½¬æ¢<img>æ ‡ç­¾ä¸ºMarkdownæ ¼å¼çš„å›¾ç‰‡ã€‚
        å¦‚æœæä¾›äº†current_urlï¼Œåˆ™å°†å›¾ç‰‡srcè½¬æ¢ä¸ºç»å¯¹è·¯å¾„ã€‚
        ä»…åšåŸºç¡€çš„Markdownå›¾ç‰‡è¯­æ³•è½¬æ¢ï¼Œä¸å†è¿›è¡Œå›¾ç‰‡åˆ†æã€‚

        :param el: BeautifulSoupçš„Tagå¯¹è±¡ï¼Œä»£è¡¨<img>å…ƒç´ ã€‚
        :param text: å›¾ç‰‡çš„æ›¿ä»£æ–‡æœ¬ï¼ˆé€šå¸¸ä¸ºç©ºï¼Œå› ä¸ºaltå±æ€§ä¼šè¢«å•ç‹¬æå–ï¼‰ã€‚
        :param parent_tags: çˆ¶æ ‡ç­¾é›†åˆï¼Œç”¨äºåˆ¤æ–­ä¸Šä¸‹æ–‡ã€‚
        :return: Markdownæ ¼å¼çš„å›¾ç‰‡å­—ç¬¦ä¸²ï¼Œæˆ–è€…åœ¨ç‰¹å®šæƒ…å†µä¸‹è¿”å›altæ–‡æœ¬æˆ–ç©ºå­—ç¬¦ä¸²ã€‚
        """
        alt_text = el.attrs.get("alt", "") or ""
        src_url = el.attrs.get("src", "") or ""
        title_text = el.attrs.get("title", "") or ""

        if (
                "_inline" in parent_tags
                and el.parent.name not in self.options["keep_inline_images_in"]
        ):
            return alt_text

        if not src_url:
            return alt_text

        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if self.current_url:
            src_url = urljoin(self.current_url, src_url)

        # ä¼˜å…ˆä½¿ç”¨AIåˆ†æç»“æœ
        if self.img_desc_map and src_url in self.img_desc_map:
            desc_info = self.img_desc_map[src_url]
            ai_title = desc_info.get("title") or alt_text or "å›¾ç‰‡"
            ai_desc = desc_info.get("description", "")
            md = f"![{ai_title}]({src_url})"
            if ai_desc:
                md += "\n" + "\n".join(f"> {line}" for line in ai_desc.strip().splitlines())
            return md

        if title_text:
            escaped_title = title_text.replace('"', r"\"")
            title_part = f' "{escaped_title}"'
        else:
            title_part = ""
        return f"![{alt_text}]({src_url}{title_part})"

    def _process_table_element(self, element):
        """
        è¾…åŠ©æ–¹æ³•ï¼šå¤„ç†åŒ…å«colspanæˆ–rowspanå±æ€§çš„è¡¨æ ¼å…ƒç´ ï¼ˆtd, thï¼‰ã€‚
        æ­¤æ–¹æ³•ä¼šè§£æä¼ å…¥çš„è¡¨æ ¼å…ƒç´ å­—ç¬¦ä¸²ï¼Œå¹¶ç§»é™¤é™¤äº†'colspan'å’Œ'rowspan'ä¹‹å¤–çš„æ‰€æœ‰å±æ€§ã€‚
        ç›®çš„æ˜¯åœ¨ä¿ç•™è¡¨æ ¼ç»“æ„çš„åŒæ—¶ï¼Œç®€åŒ–HTMLï¼Œä»¥ä¾¿åç»­å¯èƒ½ç”±å…¶ä»–å·¥å…·æˆ–æ‰‹åŠ¨è¿›è¡Œæ›´å¤æ‚çš„Markdownè½¬æ¢ã€‚

        :param element: BeautifulSoupçš„Tagå¯¹è±¡ï¼Œä»£è¡¨ä¸€ä¸ªHTMLè¡¨æ ¼å…ƒç´ ï¼ˆå¦‚<table>, <tr>, <td>, <th>ï¼‰ã€‚
        :return: å¤„ç†åçš„HTMLå…ƒç´ å­—ç¬¦ä¸²ï¼Œä»…ä¿ç•™colspanå’Œrowspanå±æ€§ã€‚
        """
        # ä½¿ç”¨BeautifulSoupè§£æä¼ å…¥çš„å…ƒç´ å­—ç¬¦ä¸²ï¼Œç¡®ä¿æ“ä½œçš„æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„DOMç»“æ„
        soup = BeautifulSoup(str(element), "html.parser")
        # éå†soupä¸­çš„æ‰€æœ‰æ ‡ç­¾
        for tag in soup.find_all(True):
            # å®šä¹‰éœ€è¦ä¿ç•™çš„å±æ€§åˆ—è¡¨
            attrs_to_keep = ["colspan", "rowspan"]
            # æ›´æ–°æ ‡ç­¾çš„å±æ€§å­—å…¸ï¼Œåªä¿ç•™åœ¨attrs_to_keepåˆ—è¡¨ä¸­çš„å±æ€§
            tag.attrs = {
                key: value for key, value in tag.attrs.items() if key in attrs_to_keep
            }
        # è¿”å›å¤„ç†åsoupçš„å­—ç¬¦ä¸²è¡¨ç¤ºå½¢å¼
        return str(soup)

    def convert_table(self, el, text, parent_tags):
        """
        è½¬æ¢<table>æ ‡ç­¾ä¸ºMarkdownæ ¼å¼ã€‚
        å¦‚æœè¡¨æ ¼ä¸­çš„<td>æˆ–<th>æ ‡ç­¾åŒ…å«colspanæˆ–rowspanå±æ€§ï¼Œ
        åˆ™è°ƒç”¨_process_table_elementæ–¹æ³•è¿”å›å¤„ç†è¿‡çš„HTMLå­—ç¬¦ä¸²ï¼ˆä¿ç•™ç»“æ„ä½†ç®€åŒ–å±æ€§ï¼‰ï¼Œ
        å¦åˆ™ï¼Œè°ƒç”¨çˆ¶ç±»çš„convert_tableæ–¹æ³•è¿›è¡Œæ ‡å‡†è½¬æ¢ã€‚

        :param el: BeautifulSoupçš„Tagå¯¹è±¡ï¼Œä»£è¡¨<table>å…ƒç´ ã€‚
        :param text: è¡¨æ ¼çš„å†…éƒ¨æ–‡æœ¬å†…å®¹ï¼ˆé€šå¸¸ç”±å­å…ƒç´ çš„è½¬æ¢ç»“æœæ‹¼æ¥è€Œæˆï¼‰ã€‚
        :param parent_tags: çˆ¶æ ‡ç­¾é›†åˆï¼Œç”¨äºåˆ¤æ–­ä¸Šä¸‹æ–‡ã€‚
        :return: Markdownæ ¼å¼çš„è¡¨æ ¼å­—ç¬¦ä¸²ï¼Œæˆ–è€…åœ¨åŒ…å«åˆå¹¶å•å…ƒæ ¼æ—¶è¿”å›å¤„ç†åçš„HTMLå­—ç¬¦ä¸²ã€‚
        """
        # ä½¿ç”¨BeautifulSoupè§£æä¼ å…¥çš„<table>å…ƒç´ å­—ç¬¦ä¸²
        soup = BeautifulSoup(str(el), "html.parser")
        # æ£€æŸ¥è¡¨æ ¼ä¸­æ˜¯å¦å­˜åœ¨ä»»ä½•å¸¦æœ‰colspanæˆ–rowspanå±æ€§çš„<td>æˆ–<th>æ ‡ç­¾
        has_colspan_or_rowspan = any(
            tag.has_attr("colspan") or tag.has_attr("rowspan")
            for tag in soup.find_all(["td", "th"])
        )
        if has_colspan_or_rowspan:
            # å¦‚æœå­˜åœ¨åˆå¹¶å•å…ƒæ ¼ï¼Œåˆ™è°ƒç”¨_process_table_elementå¤„ç†æ•´ä¸ªè¡¨æ ¼å…ƒç´ 
            # è¿”å›çš„æ˜¯ç®€åŒ–å±æ€§åçš„HTMLå­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯Markdown
            return self._process_table_element(el)
        else:
            # å¦‚æœæ²¡æœ‰åˆå¹¶å•å…ƒæ ¼ï¼Œåˆ™è°ƒç”¨çˆ¶ç±»çš„convert_tableæ–¹æ³•è¿›è¡Œæ ‡å‡†Markdownè½¬æ¢
            return super().convert_table(el, text, parent_tags)

    def convert_a(self, el, text, parent_tags):
        """
        è½¬æ¢<a>æ ‡ç­¾ï¼ˆé“¾æ¥ï¼‰ä¸ºMarkdownæ ¼å¼ã€‚
        å¦‚æœæä¾›äº†current_urlï¼Œåˆ™å°†é“¾æ¥hrefè½¬æ¢ä¸ºç»å¯¹è·¯å¾„ã€‚
        å¤„ç†è‡ªåŠ¨é“¾æ¥ï¼ˆautolinksï¼‰å’Œé»˜è®¤æ ‡é¢˜ï¼ˆdefault_titleï¼‰çš„é€‰é¡¹ã€‚

        :param el: BeautifulSoupçš„Tagå¯¹è±¡ï¼Œä»£è¡¨<a>å…ƒç´ ã€‚
        :param text: é“¾æ¥çš„æ˜¾ç¤ºæ–‡æœ¬ã€‚
        :param convert_as_inline: å¸ƒå°”å€¼ï¼ŒæŒ‡ç¤ºæ˜¯å¦åº”å°†æ­¤é“¾æ¥ä½œä¸ºå†…è”å…ƒç´ å¤„ç†ã€‚
        :return: Markdownæ ¼å¼çš„é“¾æ¥å­—ç¬¦ä¸²ï¼Œæˆ–è€…åœ¨ç‰¹å®šæƒ…å†µä¸‹è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚
        """

        # ä½¿ç”¨chompå‡½æ•°å¤„ç†é“¾æ¥æ–‡æœ¬ï¼Œåˆ†ç¦»å‰å¯¼/å°¾éšç©ºæ ¼
        prefix, suffix, text = chomp(text)
        if not text:
            # å¦‚æœé“¾æ¥æ–‡æœ¬ä¸ºç©ºï¼ˆä¾‹å¦‚ç©ºçš„<a></a>æ ‡ç­¾ï¼‰ï¼Œåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
            return ""

        # è·å–é“¾æ¥çš„hrefå’Œtitleå±æ€§
        href_url = el.get("href")
        title_text = el.get("title")

        if self.current_url and href_url:
            # å¦‚æœéœ€è¦å°†é“¾æ¥hrefè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            # ä½¿ç”¨urljoinå°†href_urlï¼ˆå¯èƒ½æ˜¯ç›¸å¯¹è·¯å¾„ï¼‰ä¸current_urlåˆå¹¶ä¸ºç»å¯¹è·¯å¾„
            href_url = urljoin(self.current_url, href_url)

        # å¤„ç†Markdownifyçš„autolinksé€‰é¡¹ï¼šå¦‚æœé“¾æ¥æ–‡æœ¬å’Œhrefç›¸åŒï¼Œä¸”æ— æ ‡é¢˜ï¼Œåˆ™ä½¿ç”¨<href>æ ¼å¼
        if (
                self.options.get("autolinks", False)  # æ£€æŸ¥autolinksé€‰é¡¹æ˜¯å¦å­˜åœ¨ä¸”ä¸ºTrue
                and text.replace(r"\_", "_")
                == href_url  # æ–‡æœ¬ï¼ˆå¤„ç†è½¬ä¹‰çš„ä¸‹åˆ’çº¿åï¼‰ä¸hrefç›¸åŒ
                and not title_text  # æ²¡æœ‰titleå±æ€§
                and not self.options.get("default_title", False)
        ):  # default_titleé€‰é¡¹æœªå¼€å¯
            return f"<{href_url}>"  # è¿”å›è‡ªåŠ¨é“¾æ¥æ ¼å¼

        # å¤„ç†Markdownifyçš„default_titleé€‰é¡¹ï¼šå¦‚æœæ²¡æœ‰titleå±æ€§ï¼Œä½†å¼€å¯äº†default_titleï¼Œåˆ™ä½¿ç”¨hrefä½œä¸ºtitle
        if self.options.get("default_title", False) and not title_text and href_url:
            title_text = href_url

        # å¤„ç†é“¾æ¥æ ‡é¢˜ï¼Œå¦‚æœå­˜åœ¨ï¼Œåˆ™è¿›è¡Œè½¬ä¹‰å¹¶æ ¼å¼åŒ–
        if title_text:
            escaped_title = title_text.replace('"', r"\"")  # è½¬ä¹‰åŒå¼•å·
            title_part = f' "{escaped_title}"'  # æ ¼å¼åŒ–ä¸º "title"
        else:
            title_part = ""  # å¦‚æœæ²¡æœ‰æ ‡é¢˜ï¼Œåˆ™ä¸ºç©º

        # è¿”å›æ ‡å‡†Markdownæ ¼å¼çš„é“¾æ¥ï¼š[text](href_url "title_text")
        # å¦‚æœhref_urlä¸ºç©ºæˆ–Noneï¼Œåˆ™åªè¿”å›å¤„ç†è¿‡çš„æ–‡æœ¬ï¼ˆprefix + text + suffixï¼‰
        return (
            f"{prefix}[{text}]({href_url}{title_part}){suffix}"
            if href_url
            else f"{prefix}{text}{suffix}"
        )

    # åŠ ç²—æ ‡ç­¾<b>çš„è½¬æ¢ï¼Œä½¿ç”¨markdownifyåº“æä¾›çš„abstract_inline_conversionè¾…åŠ©å‡½æ•°
    # self.options['strong_em_symbol'] é€šå¸¸æ˜¯ '*' æˆ– '_'
    # lambda self: 2 * self.options['strong_em_symbol'] è¡¨ç¤ºä½¿ç”¨ä¸¤ä¸ªç¬¦å·åŒ…è£¹æ–‡æœ¬ï¼Œä¾‹å¦‚ **text**
    convert_b = abstract_inline_conversion(
        lambda self: 2 * self.options.get("strong_em_symbol", "*")
    )

    # å¼ºè°ƒæ ‡ç­¾<em>æˆ–<i>çš„è½¬æ¢ï¼ŒåŒæ ·ä½¿ç”¨abstract_inline_conversion
    # lambda self: self.options['strong_em_symbol'] è¡¨ç¤ºä½¿ç”¨ä¸€ä¸ªç¬¦å·åŒ…è£¹æ–‡æœ¬ï¼Œä¾‹å¦‚ *text*
    convert_em = abstract_inline_conversion(
        lambda self: self.options.get("strong_em_symbol", "*")
    )
    convert_i = convert_em  # <i>æ ‡ç­¾é€šå¸¸ä¸<em>è¡Œä¸ºä¸€è‡´

    # åˆ é™¤çº¿æ ‡ç­¾<del>æˆ–<s>çš„è½¬æ¢
    convert_del = abstract_inline_conversion(lambda self: "~~")
    convert_s = convert_del  # <s>æ ‡ç­¾é€šå¸¸ä¸<del>è¡Œä¸ºä¸€è‡´


# åŒ¹é…Markdownå›¾ç‰‡è¯­æ³•çš„æ­£åˆ™è¡¨è¾¾å¼
IMG_TAG_RE = re.compile(r'!\[.*?\]\((https?://[^\)]+)\)', re.IGNORECASE)


def convert_url_to_markdown(
        url: str,
        add_frontmatter: bool = True,
) -> Optional[str]:
    """
    è·å–ç½‘é¡µä¸»è¦å†…å®¹ï¼Œè½¬æ¢ä¸ºå¸¦YAML Frontmatterçš„Markdownå­—ç¬¦ä¸²ã€‚
    :param url: æ–‡ç« URL
    :param add_frontmatter: æ˜¯å¦æ·»åŠ YAML frontmatter
    :return: Markdownå­—ç¬¦ä¸²æˆ–None
    """
    print(f"ğŸš€ æ­£åœ¨å¤„ç† URL: {url}\n")
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    try:
        resp = requests.get(url, headers=headers, timeout=20)
        resp.raise_for_status()

        # --- æ­¥éª¤ 1: ä½¿ç”¨trafilaturaæå–å†…å®¹ ---
        html_content = trafilatura.extract(
            resp.content,
            include_comments=False,
            include_tables=True,
            include_images=True,
            include_links=True,
        )
        json_output = trafilatura.extract(
            resp.content,
            output_format="json",
            include_comments=False,
            include_tables=True,
        )

        if not html_content and not json_output:
            print("âŒ æå–å†…å®¹å¤±è´¥ï¼Œé¡µé¢å¯èƒ½ä¸å…¼å®¹æˆ–æ— æ­£æ–‡ã€‚")
            return None

        metadata = {
            "title": "Untitled",
            "author": None,
            "date": None,
            "source": url,
        }
        data = {}
        if json_output:
            try:
                data = json.loads(json_output)
                metadata.update(
                    {
                        "title": data.get("title", "Untitled"),
                        "author": data.get("author"),
                        "date": data.get("date"),
                        "source": data.get("source") or url,
                    }
                )
            except json.JSONDecodeError:
                print("âŒ è§£ææå–çš„JSONæ•°æ®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å…ƒæ•°æ®ã€‚")

        # ä½¿ç”¨HTMLå†…å®¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•ä»JSONè·å–æ–‡æœ¬
        main_content = html_content
        if not main_content and json_output:
            try:
                data = json.loads(json_output)
                main_content = (
                        data.get("text", "")
                        or data.get("raw_text", "")
                        or data.get("content", "")
                )
            except json.JSONDecodeError:
                pass

        if not main_content:
            print("âŒ æœªèƒ½æå–åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹")
            return None

        print(f"ğŸ“ æå–åˆ°çš„å†…å®¹é•¿åº¦: {len(main_content)} å­—ç¬¦")
        if "<" in main_content and ">" in main_content:
            clean_html = main_content
        else:
            clean_html = f"<p>{main_content.replace(chr(10), '</p><p>')}</p>"

        # å…ˆè½¬æ¢ä¸ºåŸºç¡€Markdown
        converter = ImageDescMarkdownConverter(
            heading_style="ATX", wrap=True, wrap_width=80
        )
        markdown_body = converter.convert(clean_html)

        try:
            if metadata["date"]:
                parsed_date = parse(metadata["date"])
                # è½¬æ¢ä¸ºå¸¦æ—¶åŒºçš„æ ‡å‡†æ ¼å¼
                standard_date = parsed_date.astimezone(timezone.utc).strftime(
                    "%Y-%m-%d"
                )
                metadata["date"] = standard_date
            else:
                metadata["date"] = ""
        except (ValueError, TypeError):
            metadata["date"] = ""  # è§£æå¤±è´¥åˆ™ç•™ç©º

        # --- æ­¥éª¤ 6: ç»„åˆ YAML Frontmatter å’Œ Markdown æ­£æ–‡ ---
        if add_frontmatter:
            yaml_frontmatter = "---\n"
            yaml_frontmatter += f"title: \"{metadata['title']}\"\n"
            if metadata["author"]:
                yaml_frontmatter += f"author: \"{metadata['author']}\"\n"
            if metadata["date"]:
                yaml_frontmatter += f"date: {metadata['date']}\n"
            yaml_frontmatter += f"source: <{metadata['source']}>\n"
            yaml_frontmatter += "---\n\n"
        else:
            yaml_frontmatter = ""

        final_content = yaml_frontmatter + markdown_body

        return final_content

    except requests.exceptions.RequestException as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
        return None
    except Exception as e:
        print(f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None


def html2md(html: str, skip_images: bool = False) -> str:
    """
    å°†HTMLå†…å®¹è½¬æ¢ä¸ºMarkdownï¼Œæ”¯æŒè·³è¿‡å›¾ç‰‡ã€‚
    Args:
        html: HTMLå­—ç¬¦ä¸²
        skip_images: æ˜¯å¦è·³è¿‡å›¾ç‰‡æ ‡ç­¾
    Returns:
        Markdownå­—ç¬¦ä¸²
    """
    converter = ImageDescMarkdownConverter()
    if skip_images:
        # ç§»é™¤æ‰€æœ‰å›¾ç‰‡æ ‡ç­¾
        soup = BeautifulSoup(html, "html.parser")
        for img in soup.find_all("img"):
            img.decompose()
        html = str(soup)
    return converter.convert(html)


# --- ä¸»ç¨‹åºæ‰§è¡ŒåŒºåŸŸ ---
if __name__ == "__main__":
    # æ‚¨å¯ä»¥æ›¿æ¢æˆä»»ä½•æƒ³è¦æµ‹è¯•çš„æ–‡ç« é“¾æ¥
    # ç¤ºä¾‹1: æŠ€æœ¯åšå®¢
    test_url = "https://www.ruanyifeng.com/blog/2024/05/weekly-issue-299.html"

    # ç¤ºä¾‹2: æ–°é—»æ–‡ç« 
    # test_url = "https://www.theverge.com/2024/5/13/24155243/openai-gpt-4o-announcements-google-io"

    # ä».envæ–‡ä»¶è¯»å–ZHIPUçš„API KEYå’ŒBASE_URL
    from dotenv import load_dotenv

    load_dotenv()
    import os

    zhipu_api_key = os.getenv("ZHIPU_API_KEY")
    zhipu_base_url = os.getenv("ZHIPU_BASE_URL")
    zhipu_model = os.getenv("ZHIPU_MODEL")

    # è°ƒç”¨å‡½æ•°å¹¶è·å–è¿”å›çš„Markdownå­—ç¬¦ä¸²ï¼Œä¼ å…¥keyå’Œbase_url
    markdown_output = convert_url_to_markdown(
        test_url,
    )

    # å¦‚æœæˆåŠŸè·å–ï¼Œåˆ™ä¿å­˜åˆ°æ–‡ä»¶å¹¶æ‰“å°åˆ°æ§åˆ¶å°
    if markdown_output:
        # ä¿å­˜åˆ° test.md æ–‡ä»¶
        output_file = "test.md"
        try:
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(markdown_output)
            print(f"âœ… å†…å®¹å·²æˆåŠŸä¿å­˜åˆ° {output_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

        print("---------- MARKDOWN è¾“å‡ºå¼€å§‹ ----------\n")
        print(markdown_output)
        print("\n----------- MARKDOWN è¾“å‡ºç»“æŸ -----------")
