"""
åŸºç¡€å¯è§†åŒ–æ•°æ®å¢å¼ºå™¨
æä¾›å…¬å…±çš„å¯è§†åŒ–æ•°æ®å¢å¼ºåŠŸèƒ½ï¼Œæ”¯æŒå…¬å¸å’Œè¡Œä¸šä¸¤ç§ä¸åŒçš„ä½¿ç”¨åœºæ™¯
"""

import json
import asyncio
from abc import ABC, abstractmethod
import sys
from typing import List, Dict, Any, Optional
from financial_report.utils.chat import chat_no_tool
from financial_report.utils.extract_json_array import extract_json_array
from data_process.data_collector import DataCollector


class BaseVisualDataEnhancer(ABC):
    """åŸºç¡€å¯è§†åŒ–æ•°æ®å¢å¼ºå™¨æŠ½è±¡ç±»"""
    
    def __init__(
        self,
        api_key: str,
        base_url: str,
        model: str,
        data_collector: Optional[DataCollector] = None
    ):
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.data_collector = data_collector or DataCollector(api_key, base_url, model)
        self.outline_data = None  # å­˜å‚¨å¤§çº²æ•°æ®
    
    @abstractmethod
    def get_target_name_field(self) -> str:
        """è·å–ç›®æ ‡åç§°å­—æ®µï¼ˆå…¬å¸ç”¨company_nameï¼Œè¡Œä¸šç”¨industry_nameï¼‰"""
        pass
    
    @abstractmethod
    def get_analysis_system_prompt(self) -> str:
        """è·å–å¯è§†åŒ–åˆ†æçš„ç³»ç»Ÿæç¤ºè¯"""
        pass
    
    @abstractmethod
    def get_analysis_user_prompt(
        self, 
        target_name: str, 
        batch_index: int, 
        total_batches: int, 
        data_summaries: List[Dict[str, Any]]
    ) -> str:
        """è·å–å¯è§†åŒ–åˆ†æçš„ç”¨æˆ·æç¤ºè¯"""
        pass
    
    def set_outline_data(self, outline_data: Dict[str, Any]):
        """è®¾ç½®å¤§çº²æ•°æ®"""
        self.outline_data = outline_data
    
    def analyze_visualizable_data_groups(
        self,
        flattened_data: List[Dict[str, Any]],
        max_items_per_batch: int = 50,
        target_name: str = ""
    ) -> Dict[str, Any]:
        """
        åˆ†æå±•å¹³æ•°æ®ï¼Œè¯†åˆ«é€‚åˆå¯è§†åŒ–çš„æ•°æ®ç»„åˆ
        
        Args:
            flattened_data: å±•å¹³çš„æ•°æ®åˆ—è¡¨ï¼ˆåŒ…å«æ‘˜è¦ï¼‰
            max_items_per_batch: æ¯æ‰¹æœ€å¤§å¤„ç†é¡¹ç›®æ•°
            target_name: ç›®æ ‡åç§°ï¼ˆå…¬å¸åç§°æˆ–è¡Œä¸šåç§°ï¼‰
            
        Returns:
            åŒ…å«å¯è§†åŒ–æ•°æ®ç»„åˆå»ºè®®çš„å­—å…¸
        """
        print(f"ğŸ” å¼€å§‹åˆ†æå¯è§†åŒ–æ•°æ®ç»„åˆ...")
        print(f"   ğŸ“Š æ€»æ•°æ®é¡¹: {len(flattened_data)}")
        print(f"   ğŸ“¦ æ¯æ‰¹å¤„ç†: {max_items_per_batch} é¡¹")
        
        # åˆ›å»ºæ•°æ®æ‰¹æ¬¡
        batches = self._create_analysis_batches(flattened_data, max_items_per_batch)
        print(f"   ğŸ—‚ï¸ åˆ†ä¸º {len(batches)} ä¸ªæ‰¹æ¬¡")
        
        all_suggestions = []
        
        for i, batch in enumerate(batches):
            print(f"\n   ğŸ”„ åˆ†æç¬¬ {i+1}/{len(batches)} æ‰¹æ¬¡...")
            try:
                batch_suggestions = self._analyze_batch_for_visualization(
                    batch, target_name, i+1, len(batches)
                )
                
                # ç¡®ä¿ batch_suggestions æ˜¯åˆ—è¡¨ä¸”åŒ…å«å­—å…¸
                if isinstance(batch_suggestions, list):
                    valid_suggestions = [s for s in batch_suggestions if isinstance(s, dict)]
                    all_suggestions.extend(valid_suggestions)
                    print(f"   âœ… ç¬¬ {i+1} æ‰¹æ¬¡å®Œæˆï¼Œå‘ç° {len(valid_suggestions)} ä¸ªå¯è§†åŒ–å»ºè®®")
                else:
                    print(f"   âš ï¸ ç¬¬ {i+1} æ‰¹æ¬¡è¿”å›äº†éåˆ—è¡¨ç»“æœ: {type(batch_suggestions)}")
            except Exception as e:
                print(f"   âŒ ç¬¬ {i+1} æ‰¹æ¬¡åˆ†æå¤±è´¥: {e}")
                continue
        
        # åˆå¹¶å’Œå»é‡å»ºè®®
        merged_suggestions = self._merge_and_deduplicate_suggestions(all_suggestions)
        
        result = {
            self.get_target_name_field(): target_name,
            "analysis_time": "2025-01-23",
            "total_data_items": len(flattened_data),
            "batches_processed": len(batches),
            "visualization_suggestions": merged_suggestions,
            "suggestion_count": len(merged_suggestions)
        }
        
        print(f"\nâœ… å¯è§†åŒ–åˆ†æå®Œæˆï¼")
        print(f"   ğŸ“ˆ å‘ç° {len(merged_suggestions)} ä¸ªå¯è§†åŒ–å»ºè®®")
        
        return result
    
    def _create_analysis_batches(
        self, 
        data_items: List[Dict[str, Any]], 
        max_items_per_batch: int
    ) -> List[List[Dict[str, Any]]]:
        """å°†æ•°æ®åˆ†æ‰¹è¿›è¡Œåˆ†æ"""
        batches = []
        for i in range(0, len(data_items), max_items_per_batch):
            batch = data_items[i:i + max_items_per_batch]
            batches.append(batch)
        return batches
    
    def _analyze_batch_for_visualization(
        self,
        data_batch: List[Dict[str, Any]],
        target_name: str,
        batch_index: int,
        total_batches: int
    ) -> List[Dict[str, Any]]:
        """åˆ†æä¸€æ‰¹æ•°æ®ï¼Œè¯†åˆ«å¯è§†åŒ–æœºä¼š"""
        
        # æ„å»ºæ•°æ®æ‘˜è¦åˆ—è¡¨
        data_summaries = []
        for item in data_batch:
            summary_info = {
                "id": item["id"],
                self.get_target_name_field(): item.get(self.get_target_name_field(), ""),
                "title": item.get("title", ""),
                "summary": item.get("summary", "")[:500] + "..." if len(item.get("summary", "")) > 500 else item.get("summary", "")
            }
            data_summaries.append(summary_info)
        
        system_prompt = self.get_analysis_system_prompt()
        user_prompt = self.get_analysis_user_prompt(target_name, batch_index, total_batches, data_summaries)

        try:
            if not system_prompt:
                system_prompt = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚"
            response = chat_no_tool(
                user_content=user_prompt,
                system_content=system_prompt,
                api_key=self.api_key,
                base_url=self.base_url,
                model=self.model,
                temperature=0.3,
                max_tokens=8192
            )
            
            # æå–JSON
            json_str = extract_json_array(response)
            if not json_str:
                print(f"     âŒ æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„JSON: {response[:200]}...")
                return []
            
            try:
                suggestions = json.loads(json_str)
            except json.JSONDecodeError as je:
                print(f"     âŒ JSONè§£æå¤±è´¥: {je}, JSONå­—ç¬¦ä¸²: {json_str[:200]}...")
                return []
            
            # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œä¸”æ¯ä¸ªå…ƒç´ éƒ½æ˜¯å­—å…¸
            if isinstance(suggestions, dict):
                suggestions = [suggestions]
            elif not isinstance(suggestions, list):
                print(f"     âŒ è§£æç»“æœä¸æ˜¯åˆ—è¡¨æˆ–å­—å…¸: {type(suggestions)}")
                return []
            
            # è¿‡æ»¤æ‰éå­—å…¸å…ƒç´ 
            valid_suggestions = []
            for item in suggestions:
                if isinstance(item, dict):
                    valid_suggestions.append(item)
                else:
                    print(f"     âš ï¸ è·³è¿‡éå­—å…¸å…ƒç´ : {type(item)} - {item}")
            
            return valid_suggestions
            
        except Exception as e:
            print(f"     âŒ æ‰¹æ¬¡åˆ†æå¼‚å¸¸: {e}")
            return []
    
    def _merge_and_deduplicate_suggestions(
        self, 
        all_suggestions: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """åˆå¹¶å’Œå»é‡å»ºè®®"""
        if not all_suggestions:
            return []
        
        # ç®€å•çš„å»é‡é€»è¾‘ï¼šåŸºäºdata_idsçš„ç»„åˆ
        seen_combinations = set()
        unique_suggestions = []
        
        for suggestion in all_suggestions:
            # ç¡®ä¿ suggestion æ˜¯å­—å…¸ç±»å‹
            if not isinstance(suggestion, dict):
                print(f"âš ï¸ è·³è¿‡éå­—å…¸å»ºè®®: {type(suggestion)} - {suggestion}")
                continue
                
            data_ids = suggestion.get("data_ids", [])
            if not data_ids:
                continue
                
            # åˆ›å»ºç»„åˆçš„æ ‡è¯†ç¬¦
            combo_key = tuple(sorted(data_ids))
            
            if combo_key not in seen_combinations:
                seen_combinations.add(combo_key)
                unique_suggestions.append(suggestion)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {"high": 0, "medium": 1, "low": 2}
        unique_suggestions.sort(
            key=lambda x: priority_order.get(x.get("priority", "medium"), 1) if isinstance(x, dict) else 2
        )
        
        return unique_suggestions
    
    def collect_and_visualize_data(
        self,
        visualization_suggestions: List[Dict[str, Any]],
        all_data: List[Dict[str, Any]],
        max_concurrent: int = 10
    ) -> Dict[str, Any]:
        """
        æ ¹æ®å¯è§†åŒ–å»ºè®®æ”¶é›†æ•°æ®å¹¶è¿›è¡Œå¯è§†åŒ–å¤„ç†
        
        Args:
            visualization_suggestions: å¯è§†åŒ–å»ºè®®åˆ—è¡¨
            all_data: æ‰€æœ‰åŸå§‹æ•°æ®
            
        Returns:
            åŒ…å«å¯è§†åŒ–ç»“æœçš„å­—å…¸
        """
        print(f"\nğŸ“Š å¼€å§‹æ”¶é›†å’Œå¤„ç†å¯è§†åŒ–æ•°æ®...")
        print(f"   ğŸ¯ å¤„ç†å»ºè®®æ•°: {len(visualization_suggestions)}")
        
        # ä½¿ç”¨å¼‚æ­¥å¹¶å‘å¤„ç†
        return asyncio.run(self._collect_and_visualize_data_async(visualization_suggestions, all_data, max_concurrent))
    
    async def _collect_and_visualize_data_async(
        self,
        visualization_suggestions: List[Dict[str, Any]],
        all_data: List[Dict[str, Any]],
        max_concurrent: int = 10
    ) -> Dict[str, Any]:
        """å¼‚æ­¥å¹¶å‘å¤„ç†å¯è§†åŒ–å»ºè®®"""
        
        semaphore = asyncio.Semaphore(max_concurrent)
        
        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
        tasks = []
        for i, suggestion in enumerate(visualization_suggestions):
            task = self._process_single_suggestion_async(suggestion, i, all_data, semaphore)
            tasks.append(task)
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            # è¿‡æ»¤æ‰å¼‚å¸¸å’ŒNoneç»“æœ
            successful_results = [r for r in results if r is not None and not isinstance(r, Exception)]
        else:
            successful_results = []
        
        print(f"\nâœ… å¯è§†åŒ–æ•°æ®å¤„ç†å®Œæˆï¼")
        print(f"   ğŸ“ˆ æˆåŠŸå¤„ç†: {len(successful_results)} ä¸ªå¯è§†åŒ–é¡¹ç›®")
        
        return {
            "processing_time": "2025-01-23",
            "total_suggestions_processed": len(visualization_suggestions),
            "successful_visualizations": len(successful_results),
            "visualization_results": successful_results
        }
    
    async def _process_single_suggestion_async(
        self,
        suggestion: Dict[str, Any],
        index: int,
        all_data: List[Dict[str, Any]],
        semaphore: asyncio.Semaphore
    ) -> Optional[Dict[str, Any]]:
        """å¼‚æ­¥å¤„ç†å•ä¸ªå¯è§†åŒ–å»ºè®®"""
        async with semaphore:
            print(f"\n   ğŸ”„ å¤„ç†ç¬¬ {index+1} ä¸ªå»ºè®®: {suggestion.get('chart_title', 'Unknown')}")
            
            try:
                # 1. æ”¶é›†ç›¸å…³æ•°æ®
                data_ids = suggestion.get("data_ids", [])
                print(f"      ğŸ“‹ æ”¶é›†æ•°æ®ID: {data_ids}")
                
                collected_data = self.data_collector.get_data_by_ids(data_ids, all_data)
                print(f"      âœ… æˆåŠŸæ”¶é›† {len(collected_data)} ä¸ªæ•°æ®é¡¹")
                
                if not collected_data:
                    print(f"      âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æ•°æ®ï¼Œè·³è¿‡")
                    return None
                
                # 2. ç›´æ¥å°†å»ºè®®ä½œä¸ºæˆåŠŸçš„å¯è§†åŒ–ç»“æœï¼ˆå‰é¢å·²ç»ç­›é€‰è¿‡äº†ï¼‰
                print(f"      âœ… å¯è§†åŒ–å»ºè®®å¤„ç†æˆåŠŸ: {suggestion.get('chart_title', 'Unknown')}")
                
                result_item = {
                    "suggestion_index": index + 1,
                    "original_suggestion": suggestion,
                    "collected_data_count": len(collected_data),
                    "data_ids": data_ids
                }
                return result_item
                    
            except Exception as e:
                print(f"      âŒ å¤„ç†å¤±è´¥: {e}")
                return None
    
    def run_full_enhancement_process(
        self,
        flattened_data: List[Dict[str, Any]],
        target_name: str = "",
        max_concurrent: int = 10
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„æ•°æ®å¢å¼ºæµç¨‹
        
        Args:
            flattened_data: å±•å¹³çš„æ•°æ®ï¼ˆåŒ…å«æ‘˜è¦ï¼‰
            target_name: ç›®æ ‡åç§°
            max_suggestions: æœ€å¤§å¤„ç†å»ºè®®æ•°
            
        Returns:
            å®Œæ•´çš„å¤„ç†ç»“æœ
        """
        print(f"ğŸš€ å¯åŠ¨å®Œæ•´çš„å¯è§†åŒ–æ•°æ®å¢å¼ºæµç¨‹...")
        
        # æ­¥éª¤1: åˆ†æå¯è§†åŒ–æ•°æ®ç»„åˆ
        analysis_result = self.analyze_visualizable_data_groups(
            flattened_data=flattened_data,
            target_name=target_name
        )
        
        # æ­¥éª¤2: æ”¶é›†å’Œå¯è§†åŒ–æ•°æ®
        if analysis_result["suggestion_count"] > 0:
            visualization_result = self.collect_and_visualize_data(
                visualization_suggestions=analysis_result["visualization_suggestions"],
                all_data=flattened_data,
                max_concurrent=max_concurrent
            )
        else:
            print("âš ï¸ æœªå‘ç°å¯è§†åŒ–å»ºè®®ï¼Œè·³è¿‡æ•°æ®æ”¶é›†æ­¥éª¤")
            visualization_result = {
                "processing_time": "2025-01-23",
                "total_suggestions_processed": 0,
                "successful_visualizations": 0,
                "visualization_results": []
            }
        
        # åˆå¹¶ç»“æœ
        final_result = {
            "enhancement_process": "complete",
            self.get_target_name_field(): target_name,
            "analysis_phase": analysis_result,
            "visualization_phase": visualization_result,
            "summary": {
                "total_data_analyzed": len(flattened_data),
                "suggestions_generated": analysis_result["suggestion_count"],
                "successful_visualizations": visualization_result["successful_visualizations"]
            }
        }
        
        print(f"\nğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
        print(f"   ğŸ“Š åˆ†ææ•°æ®: {len(flattened_data)} é¡¹")
        print(f"   ğŸ’¡ ç”Ÿæˆå»ºè®®: {analysis_result['suggestion_count']} ä¸ª")
        print(f"   ğŸ“ˆ æˆåŠŸå¯è§†åŒ–: {visualization_result['successful_visualizations']} ä¸ª")
        
        return final_result


def save_enhancement_results(results: Dict[str, Any], output_path: str):
    """ä¿å­˜å¢å¼ºç»“æœåˆ°æ–‡ä»¶"""
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“ å¢å¼ºç»“æœå·²ä¿å­˜åˆ°: {output_path}")
