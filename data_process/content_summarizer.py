"""
å†…å®¹æ‘˜è¦ç”Ÿæˆå™¨
ä¸ºæ”¶é›†çš„æ•°æ®ç”Ÿæˆæ‘˜è¦ï¼ŒåŸºäºç°æœ‰çš„ financial_report å·¥å…·å‡½æ•°å®ç°
"""

import asyncio
import hashlib
from typing import List, Dict, Any, Optional
from financial_report.utils.calculate_tokens import OpenAITokenCalculator
from financial_report.utils.fast_token_splitter import FastTokenSplitter
from financial_report.llm_calls.info_description import (
    async_generate_full_content_description,
)


def _get_content_hash(content: str) -> str:
    """å®‰å…¨åœ°ç”Ÿæˆå†…å®¹çš„å“ˆå¸Œå€¼"""
    return hashlib.md5(content.encode("utf-8")).hexdigest()


async def _generate_summary_async(
    content: str,
    api_key: str,
    base_url: str,
    model: str,
    semaphore: asyncio.Semaphore,
    progress_counter: dict = None,
    task_id: str = "",
) -> str:
    """å¼‚æ­¥ç”Ÿæˆæ‘˜è¦ï¼Œå¸¦å¹¶å‘æ§åˆ¶å’Œè¿›åº¦æ˜¾ç¤º"""
    async with semaphore:
        if progress_counter:
            print(
                f"   ğŸ”„ [{progress_counter['current']}/{progress_counter['total']}] æ­£åœ¨ç”Ÿæˆæ‘˜è¦: {task_id[:50]}..."
            )

        try:
            result = await async_generate_full_content_description(
                content=content, api_key=api_key, base_url=base_url, model=model
            )

            if progress_counter:
                progress_counter["current"] += 1
                progress_counter["completed"] += 1
                print(
                    f"   âœ… [{progress_counter['current']}/{progress_counter['total']}] æ‘˜è¦ç”Ÿæˆå®Œæˆ: {task_id[:50]}..."
                )

            return result
        except Exception as e:
            if progress_counter:
                progress_counter["current"] += 1
                progress_counter["failed"] += 1
                print(
                    f"   âŒ [{progress_counter['current']}/{progress_counter['total']}] æ‘˜è¦ç”Ÿæˆå¤±è´¥: {task_id[:50]}... (é”™è¯¯: {str(e)[:100]})"
                )
            raise e


def generate_summaries_for_collected_data(
    data_items: List[Dict[str, Any]],
    api_key: str,
    base_url: str,
    model: str,
    chat_max_token_length: int = 8192,
    max_summary_length: int = 500,
    max_concurrent: int = 10,
) -> List[Dict[str, Any]]:
    """
    ä¸ºæ”¶é›†çš„æ•°æ®å­—å…¸åˆ—è¡¨ç”Ÿæˆæ‘˜è¦ï¼ŒåŸºäº md å†…å®¹å­—æ®µ

    Args:
        data_items: æ•°æ®å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åº”åŒ…å« 'content' æˆ– 'md' å­—æ®µ
        api_key: APIå¯†é’¥
        base_url: APIåŸºç¡€URL
        model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        chat_max_token_length: Chatæ¨¡å‹çš„æœ€å¤§tokené•¿åº¦ï¼Œç”¨äºåˆ†å—
        max_summary_length: æ‘˜è¦çš„æœ€å¤§é•¿åº¦
        max_concurrent: æœ€å¤§å¹¶å‘æ•°

    Returns:
        æ·»åŠ äº† 'summary' å­—æ®µçš„æ•°æ®å­—å…¸åˆ—è¡¨
    """
    print(f"\nğŸ“ å¼€å§‹ä¸º {len(data_items)} ä¸ªæ•°æ®é¡¹ç”Ÿæˆæ‘˜è¦...")
    print(f"ğŸ”§ é…ç½®: æœ€å¤§å¹¶å‘={max_concurrent}, æ¨¡å‹={model}")

    # åˆå§‹åŒ–tokenè®¡ç®—å™¨
    token_calculator = OpenAITokenCalculator()
    max_token_per_block = int(chat_max_token_length * 0.6)  # ä½¿ç”¨60%ä½œä¸ºåˆ†å—å¤§å°

    print(f"ğŸ”§ åˆ†å—é…ç½®:")
    print(f"   - Chatæ¨¡å‹æœ€å¤§token: {chat_max_token_length}")
    print(f"   - æ¯å—æœ€å¤§token: {max_token_per_block}")
    print(f"   - æ‘˜è¦æˆªæ–­é•¿åº¦: {max_summary_length}")

    # è¿è¡Œå¼‚æ­¥å¤„ç†
    return asyncio.run(
        _process_summaries_async(
            data_items=data_items,
            api_key=api_key,
            base_url=base_url,
            model=model,
            max_summary_length=max_summary_length,
            max_token_per_block=max_token_per_block,
            token_calculator=token_calculator,
            max_concurrent=max_concurrent,
        )
    )


async def _process_summaries_async(
    data_items: List[Dict[str, Any]],
    api_key: str,
    base_url: str,
    model: str,
    max_summary_length: int,
    max_token_per_block: int,
    token_calculator,
    max_concurrent: int = 10,
) -> List[Dict[str, Any]]:
    """å¼‚æ­¥å¤„ç†æ‰€æœ‰æ•°æ®é¡¹çš„æ‘˜è¦ç”Ÿæˆï¼Œå¸¦å¹¶å‘æ§åˆ¶å’Œå†…å®¹å»é‡"""

    semaphore = asyncio.Semaphore(max_concurrent)

    # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰éœ€è¦ç”Ÿæˆæ‘˜è¦çš„å†…å®¹ï¼Œå¹¶è¿›è¡Œå»é‡
    print("ğŸ” ç¬¬ä¸€æ­¥: åˆ†ææ•°æ®å†…å®¹å¹¶è¿›è¡Œå»é‡...")

    content_to_items = {}  # content_hash -> list of items
    content_to_blocks = (
        {}
    )  # content_hash -> list of (item_index, block_index, block_content)

    # ç»Ÿè®¡å˜é‡
    items_need_summary = []
    items_already_have_summary = 0
    
    for i, item in enumerate(data_items):
        if not item.get("summary"):
            items_need_summary.append((i, item))
        else:
            items_already_have_summary += 1

    total_items_to_analyze = len(items_need_summary)
    
    if items_already_have_summary > 0:
        print(f"ğŸ“‹ è·³è¿‡å·²æœ‰æ‘˜è¦çš„æ•°æ®é¡¹: {items_already_have_summary} ä¸ª")
    
    if total_items_to_analyze == 0:
        print("âœ… æ‰€æœ‰æ•°æ®é¡¹éƒ½å·²æœ‰æ‘˜è¦ï¼Œæ— éœ€ç”Ÿæˆ")
        return data_items
    analyzed_count = 0
    long_items_count = 0
    total_blocks_created = 0

    for item_index, item in items_need_summary:
        analyzed_count += 1

        # è·å–å†…å®¹ï¼Œä¼˜å…ˆä½¿ç”¨ 'content' å­—æ®µï¼Œå…¶æ¬¡æ˜¯ 'md' å­—æ®µ
        content = item.get("content") or item.get("md", "")
        if not content:
            print(f"   âš ï¸  è·³è¿‡ç©ºå†…å®¹é¡¹: {item.get('title', 'unknown')}")
            continue

        # æ˜¾ç¤ºtokenè®¡ç®—è¿›åº¦
        if analyzed_count % 10 == 0 or analyzed_count == total_items_to_analyze:
            print(
                f"   ğŸ”¢ [{analyzed_count}/{total_items_to_analyze}] Tokenè®¡ç®—è¿›åº¦: {(analyzed_count/total_items_to_analyze*100):.1f}%"
            )

        token_count = token_calculator.count_tokens(content)

        if token_count <= max_token_per_block:
            # å†…å®¹ä¸è¶…é™ï¼Œç›´æ¥ç”Ÿæˆæ‘˜è¦
            content_hash = _get_content_hash(content)
            if content_hash not in content_to_items:
                content_to_items[content_hash] = []
            content_to_items[content_hash].append((item_index, item))
        else:
            # å†…å®¹è¶…é™ï¼Œåˆ†å—å¤„ç†
            long_items_count += 1
            item_title = item.get("title", item.get("url", "unknown"))
            print(f"   ğŸ“„ å†…å®¹è¿‡é•¿éœ€åˆ†å—: {item_title[:50]}... (tokens: {token_count})")

            # å¦‚æœtokenè¶…è¿‡25ä¸‡å°±ä¸¢å¼ƒ
            if token_count > 250000:
                print(
                    f"   âš ï¸  å†…å®¹è¿‡é•¿ï¼Œè·³è¿‡: {item_title[:50]}... (tokens: {token_count})"
                )
                continue

            # ä½¿ç”¨é«˜æ€§èƒ½åˆ†å—å™¨
            splitter = FastTokenSplitter(
                token_calculator=token_calculator,
                chunk_size=max_token_per_block,
                chunk_overlap=50,  # å°çš„é‡å ä»¥ä¿æŒä¸Šä¸‹æ–‡
            )
            blocks = splitter.split_text(content)

            total_blocks_created += len(blocks)
            print(f"   âœ‚ï¸  åˆ†å—å®Œæˆ: åˆ›å»ºäº† {len(blocks)} ä¸ªå—")

            # å¯¹æ¯ä¸ªå—è¿›è¡Œå»é‡
            for block_index, block in enumerate(blocks):
                block_hash = _get_content_hash(block)
                if block_hash not in content_to_blocks:
                    content_to_blocks[block_hash] = []
                content_to_blocks[block_hash].append((item_index, block_index, block))

    print(f"   ğŸ“ˆ Tokenåˆ†æå®Œæˆç»Ÿè®¡:")
    print(f"      - åˆ†ææ•°æ®é¡¹æ€»æ•°: {total_items_to_analyze}")
    print(f"      - éœ€è¦åˆ†å—çš„é•¿å†…å®¹: {long_items_count}")
    print(f"      - åˆ›å»ºçš„æ€»å—æ•°: {total_blocks_created}")
    if long_items_count > 0:
        print(
            f"      - å¹³å‡æ¯ä¸ªé•¿å†…å®¹åˆ†å—: {(total_blocks_created/long_items_count):.1f}"
        )

    # ç»Ÿè®¡å»é‡æ•ˆæœ
    total_items = len(items_need_summary)
    unique_contents = len(content_to_items)
    unique_blocks = len(content_to_blocks)
    total_unique_tasks = unique_contents + unique_blocks

    print(f"ğŸ“Š å»é‡ç»Ÿè®¡:")
    print(f"   - éœ€è¦å¤„ç†çš„æ•°æ®é¡¹: {total_items}")
    print(f"   - å»é‡åçš„å®Œæ•´å†…å®¹: {unique_contents}")
    print(f"   - å»é‡åçš„åˆ†å—å†…å®¹: {unique_blocks}")
    print(f"   - æ€»è®¡éœ€è¦ç”Ÿæˆæ‘˜è¦: {total_unique_tasks}")
    if total_items > 0:
        print(
            f"   - å»é‡æ•ˆç‡: {((total_items - total_unique_tasks) / total_items * 100):.1f}%"
        )

    # ç¬¬äºŒæ­¥ï¼šä¸ºå»é‡åçš„å†…å®¹åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
    print("ğŸš€ ç¬¬äºŒæ­¥: åˆ›å»ºå¼‚æ­¥ä»»åŠ¡...")

    # åˆå§‹åŒ–è¿›åº¦è®¡æ•°å™¨
    progress_counter = {
        "current": 0,
        "total": total_unique_tasks,
        "completed": 0,
        "failed": 0,
    }

    unique_content_tasks = {}  # content_hash -> task
    unique_block_tasks = {}  # block_hash -> task

    # å¤„ç†å®Œæ•´å†…å®¹
    for content_hash, item_list in content_to_items.items():
        _, first_item = item_list[0]  # æ‰€æœ‰itemçš„contentéƒ½ç›¸åŒï¼Œå–ç¬¬ä¸€ä¸ª
        content = first_item.get("content") or first_item.get("md", "")
        # ç”Ÿæˆä»»åŠ¡IDç”¨äºè¿›åº¦æ˜¾ç¤º
        task_id = (
            f"å®Œæ•´å†…å®¹-{first_item.get('title', first_item.get('url', 'unknown'))}"
        )
        task = _generate_summary_async(
            content, api_key, base_url, model, semaphore, progress_counter, task_id
        )
        unique_content_tasks[content_hash] = task

    # å¤„ç†åˆ†å—å†…å®¹
    for block_hash, block_infos in content_to_blocks.items():
        item_index, block_index, block_content = block_infos[
            0
        ]  # æ‰€æœ‰blockå†…å®¹éƒ½ç›¸åŒï¼Œå–ç¬¬ä¸€ä¸ª
        item = data_items[item_index]
        # ç”Ÿæˆä»»åŠ¡IDç”¨äºè¿›åº¦æ˜¾ç¤º
        task_id = f"åˆ†å—{block_index}-{item.get('title', item.get('url', 'unknown'))}"
        task = _generate_summary_async(
            block_content,
            api_key,
            base_url,
            model,
            semaphore,
            progress_counter,
            task_id,
        )
        unique_block_tasks[block_hash] = task

    # ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œæ‰€æœ‰å»é‡åçš„ä»»åŠ¡
    print(f"âš¡ ç¬¬ä¸‰æ­¥: å¹¶å‘æ‰§è¡Œ {total_unique_tasks} ä¸ªæ‘˜è¦ç”Ÿæˆä»»åŠ¡...")
    print(f"   ğŸ“Š å®æ—¶è¿›åº¦æ˜¾ç¤º:")

    try:
        # åˆå¹¶æ‰€æœ‰ä»»åŠ¡åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­ï¼Œä»¥ä¾¿ç»Ÿä¸€å¤„ç†è¿›åº¦
        all_tasks = []
        task_to_hash = {}

        # æ·»åŠ å®Œæ•´å†…å®¹ä»»åŠ¡
        for content_hash, task in unique_content_tasks.items():
            all_tasks.append(task)
            task_to_hash[task] = ("content", content_hash)

        # æ·»åŠ åˆ†å—ä»»åŠ¡
        for block_hash, task in unique_block_tasks.items():
            all_tasks.append(task)
            task_to_hash[task] = ("block", block_hash)

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        if all_tasks:
            all_results = await asyncio.gather(*all_tasks, return_exceptions=True)

            # å°†ç»“æœåˆ†é…å›å¯¹åº”çš„å­—å…¸
            content_hash_to_result = {}
            block_hash_to_result = {}

            for task, result in zip(all_tasks, all_results):
                task_type, task_hash = task_to_hash[task]
                if task_type == "content":
                    content_hash_to_result[task_hash] = result
                else:  # block
                    block_hash_to_result[task_hash] = result
        else:
            content_hash_to_result = {}
            block_hash_to_result = {}

        # æ‰“å°æœ€ç»ˆè¿›åº¦ç»Ÿè®¡
        print(f"   ğŸ“ˆ ä»»åŠ¡æ‰§è¡Œå®Œæˆ:")
        print(f"      - å·²å®Œæˆ: {progress_counter['completed']}")
        print(f"      - å·²å¤±è´¥: {progress_counter['failed']}")
        print(f"      - æ€»è®¡: {progress_counter['total']}")

        # ç¬¬å››æ­¥ï¼šå°†ç»“æœåˆ†é…ç»™ç›¸åº”çš„æ•°æ®é¡¹
        print("ğŸ“‹ ç¬¬å››æ­¥: åˆ†é…æ‘˜è¦ç»“æœåˆ°æ•°æ®é¡¹...")

        # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„ä»»åŠ¡
        success_count = 0
        error_count = 0

        # å¤„ç†å®Œæ•´å†…å®¹
        for content_hash, item_list in content_to_items.items():
            result = content_hash_to_result.get(content_hash)
            if isinstance(result, Exception):
                _, first_item = item_list[0]
                content = first_item.get("content") or first_item.get("md", "")
                summary = content[:max_summary_length]
                error_count += 1
            else:
                summary = result[:max_summary_length] if result else ""
                success_count += 1

            # å°†ç›¸åŒå†…å®¹çš„æ‘˜è¦åˆ†é…ç»™æ‰€æœ‰ç›¸å…³æ•°æ®é¡¹
            for item_index, item in item_list:
                data_items[item_index]["summary"] = summary

        # å¤„ç†åˆ†å—å†…å®¹
        item_block_summaries = {}  # item_index -> {block_index: summary}
        for block_hash, block_infos in content_to_blocks.items():
            result = block_hash_to_result.get(block_hash)
            if isinstance(result, Exception):
                summary = block_infos[0][2][:max_summary_length]  # ä½¿ç”¨åŸå§‹å—å†…å®¹
                error_count += 1
            else:
                summary = result if result else block_infos[0][2][:max_summary_length]
                success_count += 1

            # å°†ç›¸åŒå—å†…å®¹çš„æ‘˜è¦åˆ†é…ç»™æ‰€æœ‰ç›¸å…³æ•°æ®é¡¹çš„å¯¹åº”å—
            for item_index, block_index, block_content in block_infos:
                if item_index not in item_block_summaries:
                    item_block_summaries[item_index] = {}
                item_block_summaries[item_index][block_index] = summary

        # åˆå¹¶æ¯ä¸ªæ•°æ®é¡¹çš„æ‰€æœ‰å—æ‘˜è¦
        for item_index, block_summaries in item_block_summaries.items():
            # æŒ‰å—ç´¢å¼•æ’åºå¹¶åˆå¹¶
            sorted_summaries = [
                block_summaries[i] for i in sorted(block_summaries.keys())
            ]
            data_items[item_index]["summary"] = "\n".join(sorted_summaries)[
                :max_summary_length
            ]

        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        print(f"ğŸ“ˆ æ‘˜è¦ç”Ÿæˆå®Œæˆç»Ÿè®¡:")
        print(f"   - æˆåŠŸç”Ÿæˆ: {success_count}")
        print(f"   - å¤±è´¥å›é€€: {error_count}")
        if (success_count + error_count) > 0:
            print(
                f"   - æˆåŠŸç‡: {(success_count / (success_count + error_count) * 100):.1f}%"
            )

    except Exception as e:
        print(f"âŒ æ‘˜è¦ç”Ÿæˆè¿‡ç¨‹å‡ºç°å¼‚å¸¸: {e}")
        # å¦‚æœæ•´ä¸ªè¿‡ç¨‹å¤±è´¥ï¼Œä¸ºæ‰€æœ‰æœªå¤„ç†çš„æ•°æ®é¡¹ä½¿ç”¨åŸå§‹å†…å®¹
        for item in data_items:
            if not item.get("summary"):
                content = item.get("content") or item.get("md", "")
                item["summary"] = content[:max_summary_length]

    print(f"ğŸ‰ æ‘˜è¦ç”Ÿæˆæµç¨‹å®Œæˆï¼")
    return data_items
