#!/usr/bin/env python3
"""
ç»Ÿä¸€æŠ¥å‘Šç”Ÿæˆè„šæœ¬
æ”¯æŒå…¬å¸ã€è¡Œä¸šã€å®è§‚ä¸‰ç§æŠ¥å‘Šç±»å‹çš„å‘½ä»¤è¡Œç”Ÿæˆ
åŒ…å«è‡ªåŠ¨æ•°æ®æ”¶é›†åŠŸèƒ½
"""

import argparse
import os
import sys
import traceback
import subprocess
from pathlib import Path
from dotenv import load_dotenv

from unified_report_generator import UnifiedReportGenerator
from config import get_data_collection_config, get_config


def run_data_collection(collection_type: str, **kwargs) -> bool:
    """
    è¿è¡Œæ•°æ®æ”¶é›†ç¨‹åº

    Args:
        collection_type: æ”¶é›†ç±»å‹ ('company', 'industry', 'macro')
        **kwargs: ä¼ é€’ç»™æ•°æ®æ”¶é›†çš„å‚æ•°

    Returns:
        True if successful, False otherwise
    """
    try:
        # è·å–ç»Ÿä¸€é…ç½®
        config = get_data_collection_config(collection_type)

        if collection_type == "company":
            from data_process.company_data_collection import CompanyDataCollection

            company_name = kwargs.get("company_name")
            company_code = kwargs.get("company_code", "")

            print(f"ğŸ”„ å¼€å§‹æ”¶é›† {company_name} å…¬å¸æ•°æ®...")

            collector = CompanyDataCollection(
                company_name=company_name,
                company_code=company_code,
                max_concurrent=config["max_concurrent"],
                api_key=config["api_key"],
                base_url=config["base_url"],
                model=config["model"],
                use_zhipu_search=config["use_zhipu_search"],
                zhipu_search_key=config["zhipu_search_key"],
                search_interval=config["search_interval"],
                use_existing_search_results=config["use_existing_search_results"],
            )

            results = collector.run_full_process()

            if results:
                print(f"âœ… {company_name} å…¬å¸æ•°æ®æ”¶é›†å®Œæˆ!")
                return True
            else:
                print(f"âŒ {company_name} å…¬å¸æ•°æ®æ”¶é›†å¤±è´¥!")
                return False

        elif collection_type == "industry":
            from data_process.industry_data_collection import IndustryDataCollection

            industry_name = kwargs.get("industry_name")

            print(f"ğŸ”„ å¼€å§‹æ”¶é›† {industry_name} è¡Œä¸šæ•°æ®...")

            collector = IndustryDataCollection(
                industry_name=industry_name,
                max_concurrent=config["max_concurrent"],
                api_key=config["api_key"],
                base_url=config["base_url"],
                model=config["model"],
                use_zhipu_search=config["use_zhipu_search"],
                zhipu_search_key=config["zhipu_search_key"],
                search_interval=config["search_interval"],
            )

            results = collector.run_full_process()

            if results:
                print(f"âœ… {industry_name} è¡Œä¸šæ•°æ®æ”¶é›†å®Œæˆ!")
                return True
            else:
                print(f"âŒ {industry_name} è¡Œä¸šæ•°æ®æ”¶é›†å¤±è´¥!")
                return False

        elif collection_type == "macro":
            from data_process.macro_data_collection import MacroDataCollection

            macro_name = kwargs.get("macro_name")
            time_period = kwargs.get("time", "2023-2025")
            macro_theme = f"{macro_name} ({time_period})"

            print(f"ğŸ”„ å¼€å§‹æ”¶é›† {macro_theme} å®è§‚æ•°æ®...")

            collector = MacroDataCollection(
                macro_theme=macro_theme,
                max_concurrent=config["max_concurrent"],
                api_key=config["api_key"],
                base_url=config["base_url"],
                model=config["model"],
                use_zhipu_search=config["use_zhipu_search"],
                zhipu_search_key=config["zhipu_search_key"],
                search_interval=config["search_interval"],
            )

            results = collector.run_full_process()

            if results:
                print(f"âœ… {macro_theme} å®è§‚æ•°æ®æ”¶é›†å®Œæˆ!")
                return True
            else:
                print(f"âŒ {macro_theme} å®è§‚æ•°æ®æ”¶é›†å¤±è´¥!")
                return False

        else:
            print(f"âŒ æœªçŸ¥çš„æ”¶é›†ç±»å‹: {collection_type}")
            return False

    except Exception as e:
        print(f"âŒ æ•°æ®æ”¶é›†è¿‡ç¨‹å‡ºé”™: {e}")
        traceback.print_exc()
        return False


def check_data_directory(data_directory: str, report_type: str) -> bool:
    """
    æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”åŒ…å«å¿…éœ€çš„æ–‡ä»¶

    Args:
        data_directory: æ•°æ®ç›®å½•è·¯å¾„
        report_type: æŠ¥å‘Šç±»å‹ ('company', 'industry', 'macro')

    Returns:
        True if data is complete, False otherwise
    """
    if not os.path.exists(data_directory):
        return False

    # æ ¹æ®æŠ¥å‘Šç±»å‹æ£€æŸ¥å¿…éœ€çš„æ–‡ä»¶
    if report_type == "company":
        required_files = [
            "company_outline.json",
            "flattened_company_data.json",
            "outline_data_allocation.json",
        ]
    elif report_type == "industry":
        required_files = [
            "industry_outline.json",
            "flattened_industry_data.json",
            "outline_data_allocation.json",
        ]
    elif report_type == "macro":
        required_files = [
            "macro_outline.json",
            "flattened_macro_data.json",
            "outline_data_allocation.json",
        ]
    else:
        return False

    # æ£€æŸ¥æ‰€æœ‰å¿…éœ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    for file in required_files:
        file_path = os.path.join(data_directory, file)
        if not os.path.exists(file_path):
            return False

    return True


def generate_company_report(args):
    """ç”Ÿæˆå…¬å¸ç ”ç©¶æŠ¥å‘Š"""
    company_name = args.company_name
    company_code = getattr(args, "company_code", "")

    # æ„å»ºæ•°æ®ç›®å½•è·¯å¾„
    if hasattr(args, "data_dir") and args.data_dir:
        data_directory = args.data_dir
    else:
        # é¦–å…ˆæ£€æŸ¥é€šç”¨çš„ test_company_datas ç›®å½•
        generic_data_dir = "test_company_datas"
        if os.path.exists(generic_data_dir) and check_data_directory(generic_data_dir, "company"):
            data_directory = generic_data_dir
        else:
            # å¦‚æœé€šç”¨ç›®å½•ä¸å­˜åœ¨æˆ–ä¸å®Œæ•´ï¼Œä½¿ç”¨ç‰¹å®šå‘½åè§„åˆ™
            safe_name = company_name.replace(" ", "_").replace("/", "_")
            data_directory = f"test_company_datas_{safe_name}"

    images_directory = os.path.join(data_directory, "images")

    # æ„å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
    if hasattr(args, "output") and args.output:
        output_file = args.output
    else:
        output_file = os.path.join(data_directory, f"{company_name}_research_report.md")

    print("=" * 80)
    print("ğŸ¢ å…¬å¸ç ”ç©¶æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ")
    print("=" * 80)
    print(f"ğŸ“Š å…¬å¸åç§°: {company_name}")
    if company_code:
        print(f"ğŸ“ˆ å…¬å¸ä»£ç : {company_code}")
    print(f"ğŸ“‚ æ•°æ®ç›®å½•: {data_directory}")

    try:
        # æ£€æŸ¥æ•°æ®ç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–ä¸å®Œæ•´åˆ™å…ˆæ”¶é›†æ•°æ®
        if not check_data_directory(data_directory, "company"):
            print(f"ğŸ“‚ æ•°æ®ç›®å½•ä¸å­˜åœ¨æˆ–ä¸å®Œæ•´: {data_directory}")
            print("ğŸ”„ å¼€å§‹è‡ªåŠ¨æ”¶é›†å…¬å¸æ•°æ®...")

            success = run_data_collection(
                "company", company_name=company_name, company_code=company_code
            )

            if not success:
                print("âŒ æ•°æ®æ”¶é›†å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
                return 1

            # é‡æ–°æ£€æŸ¥æ•°æ®ç›®å½•
            if not check_data_directory(data_directory, "company"):
                print("âŒ æ•°æ®æ”¶é›†å®Œæˆä½†æ•°æ®æ–‡ä»¶ä»ä¸å®Œæ•´")
                return 1

        print("âœ… æ•°æ®ç›®å½•æ£€æŸ¥é€šè¿‡")

        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = UnifiedReportGenerator.from_env(report_type="company")

        # åŠ è½½æ•°æ®
        print("ğŸ“ åŠ è½½å…¬å¸æ•°æ®æ–‡ä»¶...")
        data = generator.load_report_data(
            data_dir=data_directory,
            images_directory=(
                images_directory if os.path.exists(images_directory) else None
            ),
        )
        print("âœ… å…¬å¸æ•°æ®åŠ è½½å®Œæˆ")

        # ç”ŸæˆæŠ¥å‘Š
        print(f"ğŸ“ å¼€å§‹ç”Ÿæˆ {company_name} ç ”ç©¶æŠ¥å‘Š...")
        report = generator.generate_complete_report(
            subject_name=company_name,
            data=data,
            output_file=output_file,
            enable_chart_enhancement=True,
        )

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š å…¬å¸æŠ¥å‘Šç”Ÿæˆç»Ÿè®¡:")
        stats = report.get("generation_stats", {})
        print(f"   - æ€»ç« èŠ‚æ•°: {stats.get('total_sections', 0)}")
        print(f"   - æœ‰æ•°æ®æ”¯æ’‘: {stats.get('sections_with_data', 0)}")
        print(f"   - æ— æ•°æ®æ”¯æ’‘: {stats.get('sections_without_data', 0)}")
        print(f"   - æ€»å›¾è¡¨æ•°: {stats.get('total_charts', 0)}")

        print(f"\nğŸ‰ {company_name} å…¬å¸ç ”ç©¶æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“ æŠ¥å‘Šæ–‡ä»¶: {output_file}")

        return 0

    except Exception as e:
        print(f"âŒ å…¬å¸æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        traceback.print_exc()
        return 1


def generate_industry_report(args):
    """ç”Ÿæˆè¡Œä¸šç ”ç©¶æŠ¥å‘Š"""
    industry_name = args.industry_name

    # æ„å»ºæ•°æ®ç›®å½•è·¯å¾„
    if hasattr(args, "data_dir") and args.data_dir:
        data_directory = args.data_dir
    else:
        # é¦–å…ˆæ£€æŸ¥é€šç”¨çš„ test_industry_datas ç›®å½•
        generic_data_dir = "test_industry_datas"
        if os.path.exists(generic_data_dir) and check_data_directory(generic_data_dir, "industry"):
            data_directory = generic_data_dir
        else:
            # å¦‚æœé€šç”¨ç›®å½•ä¸å­˜åœ¨æˆ–ä¸å®Œæ•´ï¼Œä½¿ç”¨ç‰¹å®šå‘½åè§„åˆ™
            safe_name = (
                industry_name.replace(" ", "_").replace("/", "_").replace("&", "and")
            )
            data_directory = f"test_industry_datas_{safe_name}"

    images_directory = os.path.join(data_directory, "images")

    # æ„å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
    if hasattr(args, "output") and args.output:
        output_file = args.output
    else:
        output_file = os.path.join(
            data_directory, f"{industry_name}_research_report.md"
        )

    print("=" * 80)
    print("ğŸ­ è¡Œä¸šç ”ç©¶æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ")
    print("=" * 80)
    print(f"ğŸ“Š è¡Œä¸šåç§°: {industry_name}")
    print(f"ğŸ“‚ æ•°æ®ç›®å½•: {data_directory}")

    try:
        # æ£€æŸ¥æ•°æ®ç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–ä¸å®Œæ•´åˆ™å…ˆæ”¶é›†æ•°æ®
        if not check_data_directory(data_directory, "industry"):
            print(f"ğŸ“‚ æ•°æ®ç›®å½•ä¸å­˜åœ¨æˆ–ä¸å®Œæ•´: {data_directory}")
            print("ğŸ”„ å¼€å§‹è‡ªåŠ¨æ”¶é›†è¡Œä¸šæ•°æ®...")

            success = run_data_collection("industry", industry_name=industry_name)

            if not success:
                print("âŒ æ•°æ®æ”¶é›†å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
                return 1

            # é‡æ–°æ£€æŸ¥æ•°æ®ç›®å½•
            if not check_data_directory(data_directory, "industry"):
                print("âŒ æ•°æ®æ”¶é›†å®Œæˆä½†æ•°æ®æ–‡ä»¶ä»ä¸å®Œæ•´")
                return 1

        print("âœ… æ•°æ®ç›®å½•æ£€æŸ¥é€šè¿‡")

        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = UnifiedReportGenerator.from_env(report_type="industry")

        # åŠ è½½æ•°æ®
        print("ğŸ“ åŠ è½½è¡Œä¸šæ•°æ®æ–‡ä»¶...")
        data = generator.load_report_data(
            data_dir=data_directory,
            images_directory=(
                images_directory if os.path.exists(images_directory) else None
            ),
        )
        print("âœ… è¡Œä¸šæ•°æ®åŠ è½½å®Œæˆ")

        # ç”ŸæˆæŠ¥å‘Š
        print(f"ğŸ“ å¼€å§‹ç”Ÿæˆ {industry_name} ç ”ç©¶æŠ¥å‘Š...")
        report = generator.generate_complete_report(
            subject_name=industry_name,
            data=data,
            output_file=output_file,
            enable_chart_enhancement=True,
        )

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š è¡Œä¸šæŠ¥å‘Šç”Ÿæˆç»Ÿè®¡:")
        stats = report.get("generation_stats", {})
        print(f"   - æ€»ç« èŠ‚æ•°: {stats.get('total_sections', 0)}")
        print(f"   - æœ‰æ•°æ®æ”¯æ’‘: {stats.get('sections_with_data', 0)}")
        print(f"   - æ— æ•°æ®æ”¯æ’‘: {stats.get('sections_without_data', 0)}")
        print(f"   - æ€»å›¾è¡¨æ•°: {stats.get('total_charts', 0)}")

        print(f"\nğŸ‰ {industry_name} è¡Œä¸šç ”ç©¶æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“ æŠ¥å‘Šæ–‡ä»¶: {output_file}")

        return 0

    except Exception as e:
        print(f"âŒ è¡Œä¸šæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        traceback.print_exc()
        return 1


def generate_macro_report(args):
    """ç”Ÿæˆå®è§‚ç ”ç©¶æŠ¥å‘Š"""
    macro_name = args.macro_name
    time_period = getattr(args, "time", "2023-2025")

    # æ„å»ºå®Œæ•´çš„å®è§‚ä¸»é¢˜åç§°
    macro_theme = f"{macro_name} ({time_period})"

    # æ„å»ºæ•°æ®ç›®å½•è·¯å¾„
    if hasattr(args, "data_dir") and args.data_dir:
        data_directory = args.data_dir
    else:
        # é¦–å…ˆæ£€æŸ¥é€šç”¨çš„ test_macro_datas ç›®å½•
        generic_data_dir = "test_macro_datas"
        if os.path.exists(generic_data_dir) and check_data_directory(
            generic_data_dir, "macro"
        ):
            data_directory = generic_data_dir
        else:
            # å¦‚æœé€šç”¨ç›®å½•ä¸å­˜åœ¨æˆ–ä¸å®Œæ•´ï¼Œä½¿ç”¨ç‰¹å®šå‘½åè§„åˆ™
            safe_name = (
                macro_name.replace(" ", "_").replace("/", "_").replace("&", "and")
            )
            data_directory = f"test_macro_datas_{safe_name}"

    images_directory = os.path.join(data_directory, "images")

    # æ„å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
    if hasattr(args, "output") and args.output:
        output_file = args.output
    else:
        output_file = os.path.join(
            data_directory, f"{macro_name}_{time_period}_research_report.md"
        )

    print("=" * 80)
    print("ğŸŒ å®è§‚ç ”ç©¶æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ")
    print("=" * 80)
    print(f"ğŸ“Š å®è§‚ä¸»é¢˜: {macro_name}")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {time_period}")
    print(f"ğŸ“‚ æ•°æ®ç›®å½•: {data_directory}")

    try:
        # æ£€æŸ¥æ•°æ®ç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–ä¸å®Œæ•´åˆ™å…ˆæ”¶é›†æ•°æ®
        if not check_data_directory(data_directory, "macro"):
            print(f"ğŸ“‚ æ•°æ®ç›®å½•ä¸å­˜åœ¨æˆ–ä¸å®Œæ•´: {data_directory}")
            print("ğŸ”„ å¼€å§‹è‡ªåŠ¨æ”¶é›†å®è§‚æ•°æ®...")

            success = run_data_collection(
                "macro", macro_name=macro_name, time=time_period
            )

            if not success:
                print("âŒ æ•°æ®æ”¶é›†å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
                return 1

            # é‡æ–°æ£€æŸ¥æ•°æ®ç›®å½•
            if not check_data_directory(data_directory, "macro"):
                print("âŒ æ•°æ®æ”¶é›†å®Œæˆä½†æ•°æ®æ–‡ä»¶ä»ä¸å®Œæ•´")
                return 1

        print("âœ… æ•°æ®ç›®å½•æ£€æŸ¥é€šè¿‡")

        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = UnifiedReportGenerator.from_env(report_type="macro")

        # åŠ è½½æ•°æ®
        print("ğŸ“ åŠ è½½å®è§‚æ•°æ®æ–‡ä»¶...")
        data = generator.load_report_data(
            data_dir=data_directory,
            images_directory=(
                images_directory if os.path.exists(images_directory) else None
            ),
        )
        print("âœ… å®è§‚æ•°æ®åŠ è½½å®Œæˆ")

        # ç”ŸæˆæŠ¥å‘Š
        print(f"ğŸ“ å¼€å§‹ç”Ÿæˆ {macro_theme} ç ”ç©¶æŠ¥å‘Š...")
        report = generator.generate_complete_report(
            subject_name=macro_theme,
            data=data,
            output_file=output_file,
            enable_chart_enhancement=True,
        )

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š å®è§‚æŠ¥å‘Šç”Ÿæˆç»Ÿè®¡:")
        stats = report.get("generation_stats", {})
        print(f"   - æ€»ç« èŠ‚æ•°: {stats.get('total_sections', 0)}")
        print(f"   - æœ‰æ•°æ®æ”¯æ’‘: {stats.get('sections_with_data', 0)}")
        print(f"   - æ— æ•°æ®æ”¯æ’‘: {stats.get('sections_without_data', 0)}")
        print(f"   - æ€»å›¾è¡¨æ•°: {stats.get('total_charts', 0)}")

        print(f"\nğŸ‰ {macro_theme} å®è§‚ç ”ç©¶æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“ æŠ¥å‘Šæ–‡ä»¶: {output_file}")

        return 0

    except Exception as e:
        print(f"âŒ å®è§‚æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        traceback.print_exc()
        return 1


def main():
    """ä¸»ç¨‹åºå…¥å£"""

    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()

    # æ˜¾ç¤ºé…ç½®çŠ¶æ€
    print("ğŸ”§ æ£€æŸ¥é…ç½®çŠ¶æ€...")
    config = get_config()
    validation = config.validate_config()

    missing_configs = [k for k, v in validation.items() if not v]
    if missing_configs:
        print(f"âš ï¸ ç¼ºå°‘é…ç½®: {missing_configs}")
        print("ğŸ’¡ è¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®")
    else:
        print("âœ… é…ç½®æ£€æŸ¥é€šè¿‡")

    # åˆ›å»ºä¸»è§£æå™¨
    parser = argparse.ArgumentParser(
        description="ç»Ÿä¸€ç ”ç©¶æŠ¥å‘Šç”Ÿæˆå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

å…¬å¸æŠ¥å‘Š:
  python generate_report.py company --company_name "å•†æ±¤ç§‘æŠ€" --company_code "00020.HK"
  python generate_report.py company --company_name "4Paradigm"

è¡Œä¸šæŠ¥å‘Š:
  python generate_report.py industry --industry_name "æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡"
  python generate_report.py industry --industry_name "ä¸­å›½æ™ºèƒ½æœåŠ¡æœºå™¨äººäº§ä¸š"

å®è§‚æŠ¥å‘Š:
  python generate_report.py macro --macro_name "ç”Ÿæˆå¼AIåŸºå»ºä¸ç®—åŠ›æŠ•èµ„è¶‹åŠ¿" --time "2023-2026"
  python generate_report.py macro --macro_name "äººå·¥æ™ºèƒ½+æ”¿ç­–æ•ˆæœè¯„ä¼°" --time "2023-2025"
        """,
    )

    # æ·»åŠ å­å‘½ä»¤
    subparsers = parser.add_subparsers(dest="command", help="æŠ¥å‘Šç±»å‹")

    # å…¬å¸æŠ¥å‘Šå­å‘½ä»¤
    company_parser = subparsers.add_parser("company", help="ç”Ÿæˆå…¬å¸ç ”ç©¶æŠ¥å‘Š")
    company_parser.add_argument("--company_name", required=True, help="å…¬å¸åç§°")
    company_parser.add_argument("--company_code", help="å…¬å¸ä»£ç  (å¯é€‰)")
    company_parser.add_argument("--data_dir", help="è‡ªå®šä¹‰æ•°æ®ç›®å½•è·¯å¾„")
    company_parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")

    # è¡Œä¸šæŠ¥å‘Šå­å‘½ä»¤
    industry_parser = subparsers.add_parser("industry", help="ç”Ÿæˆè¡Œä¸šç ”ç©¶æŠ¥å‘Š")
    industry_parser.add_argument("--industry_name", required=True, help="è¡Œä¸šåç§°")
    industry_parser.add_argument("--data_dir", help="è‡ªå®šä¹‰æ•°æ®ç›®å½•è·¯å¾„")
    industry_parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")

    # å®è§‚æŠ¥å‘Šå­å‘½ä»¤
    macro_parser = subparsers.add_parser("macro", help="ç”Ÿæˆå®è§‚ç ”ç©¶æŠ¥å‘Š")
    macro_parser.add_argument("--macro_name", required=True, help="å®è§‚ä¸»é¢˜åç§°")
    macro_parser.add_argument(
        "--time", default="2023-2025", help="æ—¶é—´èŒƒå›´ (é»˜è®¤: 2023-2025)"
    )
    macro_parser.add_argument("--data_dir", help="è‡ªå®šä¹‰æ•°æ®ç›®å½•è·¯å¾„")
    macro_parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")

    # è§£æå‚æ•°
    args = parser.parse_args()

    # æ£€æŸ¥æ˜¯å¦æä¾›äº†å­å‘½ä»¤
    if not args.command:
        parser.print_help()
        return 1

    # æ ¹æ®å‘½ä»¤ç±»å‹è°ƒç”¨ç›¸åº”çš„å¤„ç†å‡½æ•°
    try:
        if args.command == "company":
            return generate_company_report(args)
        elif args.command == "industry":
            return generate_industry_report(args)
        elif args.command == "macro":
            return generate_macro_report(args)
        else:
            print(f"âŒ æœªçŸ¥çš„å‘½ä»¤ç±»å‹: {args.command}")
            return 1

    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
