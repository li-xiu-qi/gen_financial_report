"""
å…¬å¸æŠ¥å‘Šç”Ÿæˆå™¨
åŸºäºåŸºç¡€æ¡†æ¶å®ç°çš„å…¬å¸ç ”æŠ¥ç”Ÿæˆå™¨
"""

import os
import json
import asyncio
import traceback
from typing import List, Dict, Any
from data_process.base_report_generator import BaseReportGenerator
from data_process.company_report_data_processor import CompanyReportDataProcessor
from data_process.company_report_content_assembler import CompanyReportContentAssembler
from financial_report.utils.chat import chat_no_tool


# ====================
# æç¤ºè¯æ¨¡æ¿å®šä¹‰åŒºåŸŸ
# ====================

# æœ‰æ•°æ®æ”¯æ’‘çš„ç« èŠ‚å†…å®¹ç”Ÿæˆæç¤ºè¯ - ç”¨äºåŸºäºæ”¶é›†åˆ°çš„æ•°æ®ç”Ÿæˆä¸“ä¸šçš„ç ”æŠ¥ç« èŠ‚å†…å®¹
COMPANY_SECTION_WITH_DATA_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é‡‘èåˆ†æå¸ˆå’Œç ”ç©¶ä¸“å®¶ï¼Œå…·æœ‰å¤šå¹´æŠ•èµ„é“¶è¡Œå’Œè¯åˆ¸ç ”ç©¶ç»éªŒã€‚ä½ æ­£åœ¨æ’°å†™{subject_name}çš„ä¸“ä¸šç ”ç©¶æŠ¥å‘Šç« èŠ‚å†…å®¹ã€‚

é‡è¦è¯´æ˜ï¼š
- ä½ åªéœ€è¦ç”Ÿæˆç« èŠ‚çš„æ­£æ–‡å†…å®¹ï¼Œä¸è¦ç”Ÿæˆç« èŠ‚æ ‡é¢˜
- ä¸è¦åœ¨å¼€å¤´é‡å¤ç« èŠ‚æ ‡é¢˜
- ç›´æ¥ä»åˆ†æå†…å®¹å¼€å§‹å†™ä½œ
- ä¸è¦åœ¨æ–‡æœ«æ·»åŠ å‚è€ƒæ–‡çŒ®åˆ—è¡¨æˆ–å¼•ç”¨è¯´æ˜
- åªåœ¨æ­£æ–‡ä¸­éœ€è¦å¼•ç”¨æ•°æ®æ—¶ä½¿ç”¨[åºå·]æ ¼å¼å³å¯
- åªèƒ½ä½¿ç”¨ä¸‰çº§æ ‡é¢˜ï¼ˆ###ï¼‰åŠä»¥ä¸‹çš„æ ‡é¢˜ï¼ŒäºŒçº§æ ‡é¢˜ï¼ˆ##ï¼‰ç”±æˆ‘ä»¬æ‰‹åŠ¨æ§åˆ¶ï¼Œä¸èƒ½ä½¿ç”¨

ä½ çš„ä¸“ä¸šç‰¹é•¿ï¼š
1. æ·±åº¦è´¢åŠ¡åˆ†æå’Œä¼°å€¼å»ºæ¨¡
2. è¡Œä¸šè¶‹åŠ¿ç ”ç©¶å’Œç«äº‰æ ¼å±€åˆ†æ
3. å…¬å¸æˆ˜ç•¥å’Œå•†ä¸šæ¨¡å¼è¯„ä¼°
4. é£é™©è¯†åˆ«å’ŒæŠ•èµ„å»ºè®®åˆ¶å®š

å†™ä½œè¦æ±‚ï¼š
1. **æ·±åº¦åˆ†æ**: åŸºäºæä¾›çš„æ•°æ®è¿›è¡Œæ·±å…¥ã€å¤šç»´åº¦çš„åˆ†æï¼Œä¸è¦æµ…å°è¾„æ­¢
2. **ä¸“ä¸šä¸¥è°¨**: ä½¿ç”¨ä¸“ä¸šçš„é‡‘èæœ¯è¯­å’Œåˆ†ææ¡†æ¶ï¼Œç¡®ä¿é€»è¾‘æ¸…æ™°
3. **æ•°æ®é©±åŠ¨**: å……åˆ†å¼•ç”¨å’Œåˆ†æå…·ä½“æ•°æ®ï¼Œç”¨æ•°å­—è¯´è¯
4. **æ´å¯Ÿç‹¬åˆ°**: æä¾›æœ‰ä»·å€¼çš„è¡Œä¸šæ´å¯Ÿå’ŒæŠ•èµ„è§‚ç‚¹
5. **æ ¼å¼è§„èŒƒ**: ä½¿ç”¨æ ‡å‡†çš„æ®µè½æ ¼å¼ï¼Œç»“æ„åˆç†
6. **å¼•ç”¨è§„èŒƒ**: åœ¨å¼•ç”¨æ•°æ®æ—¶ä½¿ç”¨å‚è€ƒæ–‡çŒ®æ ¼å¼ï¼ˆå¦‚[1]ã€[2]ç­‰ï¼‰ï¼Œåœ¨å¼•ç”¨å›¾è¡¨æ—¶ä½¿ç”¨"è§å›¾X"æ ¼å¼

å›¾è¡¨å¼•ç”¨æŒ‡å¯¼ï¼š
- å½“åˆ†ææ¶‰åŠè¶‹åŠ¿ã€å¯¹æ¯”ã€ç»“æ„ç­‰å¯è§†åŒ–æ•°æ®æ—¶ï¼Œè¯·ä½¿ç”¨"è§å›¾X"æ ¼å¼å¼•ç”¨ç›¸å…³å›¾è¡¨
- å›¾è¡¨å¼•ç”¨åº”è¯¥ä¸åˆ†æå†…å®¹ç´§å¯†ç»“åˆï¼Œå¢å¼ºè®ºè¯æ•ˆæœ
- æ¯ä¸ªé‡è¦çš„æ•°æ®åˆ†æç‚¹éƒ½åº”è¯¥è€ƒè™‘æ˜¯å¦æœ‰å¯¹åº”çš„å›¾è¡¨æ”¯æ’‘

å†…å®¹æ·±åº¦è¦æ±‚ï¼š
- æ¯ä¸ªè¦ç‚¹éƒ½è¦æœ‰å…·ä½“çš„æ•°æ®æ”¯æ’‘å’Œåˆ†æè®ºè¯
- åŒ…å«æ¨ªå‘å¯¹æ¯”å’Œçºµå‘è¶‹åŠ¿åˆ†æ
- ç»“åˆè¡Œä¸šèƒŒæ™¯å’Œå®è§‚ç¯å¢ƒè¿›è¡Œåˆ†æ
- æä¾›å…·ä½“çš„æŠ•èµ„é€»è¾‘å’Œé£é™©æç¤º

æ–‡å­—è¦æ±‚ï¼š
- å†…å®¹è¯¦å®ï¼Œå•ä¸ªç« èŠ‚å­—æ•°åœ¨2000-3500å­—ä¹‹é—´
- é¿å…ç©ºæ´çš„è¡¨è¿°ï¼Œæ¯å¥è¯éƒ½è¦æœ‰å®é™…ä»·å€¼
- ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€ï¼Œé€‚åˆæœºæ„æŠ•èµ„è€…é˜…è¯»

é‡è¦æé†’ï¼š
- å½“å¼•ç”¨æ•°æ®æ—¶ï¼Œè¯·ä½¿ç”¨æ–¹æ‹¬å·æ ¼å¼å¦‚[1]ã€[2]ï¼Œä¸è¦ä½¿ç”¨ã€æ•°æ®123ã€‘æ ¼å¼
- å½“å¼•ç”¨å›¾è¡¨æ—¶ï¼Œè¯·ä½¿ç”¨"è§å›¾X"æ ¼å¼ï¼Œå…¶ä¸­Xæ˜¯å›¾è¡¨ç¼–å·
- è¯·ç›´æ¥å¼€å§‹æ­£æ–‡å†…å®¹ï¼Œä¸è¦é‡å¤ç« èŠ‚æ ‡é¢˜
- ä¸è¦åœ¨æ–‡æœ«æ·»åŠ "å‚è€ƒæ–‡çŒ®"ã€"å¼•ç”¨æ•°æ®"ç­‰è¯´æ˜æ€§å†…å®¹
- æ­£æ–‡ç»“æŸå³å¯ï¼Œæ— éœ€é¢å¤–è¯´æ˜

è¯·ä¸º{subject_name}æ’°å†™ä»¥ä¸‹ç« èŠ‚çš„æ­£æ–‡å†…å®¹ï¼š

**ç« èŠ‚ä¸»é¢˜**: {section_title}

**åˆ†ææ¡†æ¶å’Œè¦ç‚¹**:
{points_text}

**æ”¯æ’‘æ•°æ®**:
{data_content}{chart_content}

**æ’°å†™è¦æ±‚**:

1. **æ­£æ–‡å†…å®¹**: ç›´æ¥å¼€å§‹æ­£æ–‡ï¼Œä¸è¦é‡å¤ç« èŠ‚æ ‡é¢˜
2. **åˆ†ææ·±åº¦**: å¯¹å…³é”®æ•°æ®è¿›è¡Œæ·±å…¥è§£è¯»å’Œåˆ†æ
3. **æ•°æ®åº”ç”¨**: å……åˆ†å¼•ç”¨æä¾›çš„æ•°æ®æ”¯æ’‘è§‚ç‚¹ï¼Œä½¿ç”¨[åºå·]æ ¼å¼å¼•ç”¨
4. **å›¾è¡¨é›†æˆ**: åœ¨åˆé€‚çš„ä½ç½®ä½¿ç”¨"è§å›¾X"æ ¼å¼å¼•ç”¨å›¾è¡¨ï¼Œå¢å¼ºåˆ†æè¯´æœåŠ›
5. **ä¸“ä¸šæ°´å‡†**: ä½¿ç”¨ä¸“ä¸šçš„åˆ†ææ¡†æ¶å’Œæ–¹æ³•è®º
6. **å­—æ•°è¦æ±‚**: å†…å®¹è¯¦å®å……åˆ†ï¼Œç›®æ ‡å­—æ•°2000-3000å­—

è¯·æ’°å†™ä¸“ä¸šã€æ·±å…¥çš„ç« èŠ‚æ­£æ–‡å†…å®¹ï¼Œä¸åŒ…å«ç« èŠ‚æ ‡é¢˜ã€‚æ³¨æ„åœ¨é€‚å½“ä½ç½®å¼•ç”¨å›¾è¡¨æ¥æ”¯æ’‘åˆ†æè§‚ç‚¹ã€‚"""

# æ— æ•°æ®æ”¯æ’‘çš„ç« èŠ‚æ¡†æ¶ç”Ÿæˆæç¤ºè¯ - ç”¨äºåœ¨ç¼ºä¹å…·ä½“æ•°æ®æ—¶ç”Ÿæˆåˆ†ææ¡†æ¶å’ŒæŒ‡å¯¼æ€§å†…å®¹
COMPANY_SECTION_WITHOUT_DATA_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆå’Œè¡Œä¸šä¸“å®¶ã€‚éœ€è¦ä¸º{subject_name}çš„ç ”ç©¶æŠ¥å‘Šæ’°å†™ç« èŠ‚æ­£æ–‡å†…å®¹ã€‚

é‡è¦è¯´æ˜ï¼š
- ä½ åªéœ€è¦ç”Ÿæˆç« èŠ‚çš„æ­£æ–‡å†…å®¹ï¼Œä¸è¦ç”Ÿæˆç« èŠ‚æ ‡é¢˜
- ä¸è¦åœ¨å¼€å¤´é‡å¤ç« èŠ‚æ ‡é¢˜
- ç›´æ¥ä»åˆ†æå†…å®¹å¼€å§‹å†™ä½œ
- ä¸è¦åœ¨æ–‡æœ«æ·»åŠ ä»»ä½•è¯´æ˜æ€§å†…å®¹
- åªèƒ½ä½¿ç”¨ä¸‰çº§æ ‡é¢˜ï¼ˆ###ï¼‰åŠä»¥ä¸‹çš„æ ‡é¢˜ï¼ŒäºŒçº§æ ‡é¢˜ï¼ˆ##ï¼‰ç”±æˆ‘ä»¬æ‰‹åŠ¨æ§åˆ¶ï¼Œä¸èƒ½ä½¿ç”¨

è™½ç„¶ç›®å‰ç¼ºä¹å…·ä½“çš„æ•°æ®æ”¯æ’‘ï¼Œä½†ä½ éœ€è¦åŸºäºè¡Œä¸šçŸ¥è¯†å’Œä¸“ä¸šåˆ†ææ¡†æ¶ï¼Œæä¾›ï¼š
1. ä¸“ä¸šçš„åˆ†ææ€è·¯å’Œé€»è¾‘ç»“æ„
2. å…³é”®çš„åˆ†æè¦ç‚¹å’Œå…³æ³¨å› ç´   
3. è¡Œä¸šæ ‡å‡†çš„åˆ†ææ–¹æ³•å’ŒæŒ‡æ ‡
4. é’ˆå¯¹è¯¥ç±»å‹å…¬å¸çš„é€šç”¨åˆ†ææ¡†æ¶

è¦æ±‚ï¼š
- å†…å®¹ä¸“ä¸šä¸”å…·æœ‰æŒ‡å¯¼æ„ä¹‰
- æä¾›å…·ä½“çš„åˆ†æç»´åº¦å’Œè¯„ä¼°æ ‡å‡†
- ä¸ºåç»­æ•°æ®è¡¥å……ç•™å‡ºæ¥å£
- å­—æ•°æ§åˆ¶åœ¨2000-3000å­—
- ç›´æ¥å¼€å§‹æ­£æ–‡ï¼Œä¸è¦é‡å¤ç« èŠ‚æ ‡é¢˜
- ä¸è¦åœ¨æ–‡æœ«æ·»åŠ ä»»ä½•æ€»ç»“æˆ–è¯´æ˜

è¯·ä¸º{subject_name}æ’°å†™ä»¥ä¸‹ç« èŠ‚çš„åˆ†ææ¡†æ¶æ­£æ–‡ï¼š

**ç« èŠ‚ä¸»é¢˜**: {section_title}

**åˆ†æè¦ç‚¹**:
{points_text}

**æ’°å†™è¦æ±‚**:
1. **åˆ†ææ€è·¯**: å»ºç«‹è¯¥ç« èŠ‚çš„æ ¸å¿ƒåˆ†æé€»è¾‘å’Œæ¡†æ¶
2. **å…³é”®æŒ‡æ ‡**: æ˜ç¡®åº”å…³æ³¨çš„æ ¸å¿ƒæŒ‡æ ‡å’Œè¯„ä¼°æ ‡å‡†
3. **åˆ†ææ–¹æ³•**: æä¾›ä¸“ä¸šçš„åˆ†ææ–¹æ³•å’Œè¯„ä¼°å·¥å…·
4. **å…³æ³¨è¦ç´ **: è¯†åˆ«å½±å“è¯¥é¢†åŸŸçš„å…³é”®å› ç´ 
5. **æ•°æ®ç±»å‹**: è¯´æ˜ç†æƒ³æƒ…å†µä¸‹éœ€è¦å“ªäº›ç±»å‹çš„æ•°æ®
6. **è¡Œä¸šå¯¹æ¯”**: æä¾›è¡Œä¸šæ ‡æ†å’Œå¯¹æ¯”ç»´åº¦

æ³¨æ„ï¼šè¯·ç›´æ¥å¼€å§‹æ­£æ–‡å†…å®¹ï¼Œä¸è¦é‡å¤ç« èŠ‚æ ‡é¢˜ã€‚
"""


class CompanyReportGenerator(BaseReportGenerator):

    def _create_data_processor(self):
        """åˆ›å»ºå…¬å¸æŠ¥å‘Šæ•°æ®å¤„ç†å™¨"""
        return CompanyReportDataProcessor()
    
    def _create_content_assembler(self):
        """åˆ›å»ºå…¬å¸æŠ¥å‘Šå†…å®¹ç»„è£…å™¨"""
        return CompanyReportContentAssembler()
    
    def get_section_with_data_prompt(self) -> str:
        """è·å–æœ‰æ•°æ®æ”¯æ’‘çš„ç« èŠ‚å†…å®¹ç”Ÿæˆæç¤ºè¯"""
        return COMPANY_SECTION_WITH_DATA_PROMPT
    
    def get_section_without_data_prompt(self) -> str:
        """è·å–æ— æ•°æ®æ”¯æ’‘çš„ç« èŠ‚æ¡†æ¶ç”Ÿæˆæç¤ºè¯"""
        return COMPANY_SECTION_WITHOUT_DATA_PROMPT
    
    def generate_complete_report_with_visualization(
        self,
        subject_name: str,
        outline_data: Dict[str, Any],
        allocation_result: Dict[str, Any],
        all_flattened_data: List[Dict[str, Any]],
        images_dir: str,
        visualization_results: Dict[str, Any] = None,
        output_file: str = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¸¦æœ‰å¯è§†åŒ–å¢å¼ºçš„å®Œæ•´ç ”ç©¶æŠ¥å‘Šï¼ˆä¸¤è½®ç”Ÿæˆæ¨¡å¼ï¼‰
        
        Args:
            subject_name: ç ”ç©¶ä¸»ä½“åç§°ï¼ˆå…¬å¸åï¼‰
            outline_data: å¤§çº²æ•°æ®
            allocation_result: æ•°æ®åˆ†é…ç»“æœ
            all_flattened_data: æ‰€æœ‰å±•å¹³æ•°æ®
            images_dir: å›¾ç‰‡ç›®å½•è·¯å¾„
            visualization_results: å¯è§†åŒ–ç»“æœï¼ˆå¯é€‰ï¼‰
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šå†…å®¹
        """
        print(f"\nğŸ¨ å¼€å§‹ç”Ÿæˆ {subject_name} å¯è§†åŒ–å¢å¼ºç ”ç©¶æŠ¥å‘Š...")
        
        # ====== ç¬¬ä¸€è½®ï¼šç”ŸæˆåŸºç¡€å†…å®¹ ======
        print("\nğŸ”„ ç¬¬ä¸€è½®ï¼šç”ŸæˆåŸºç¡€æŠ¥å‘Šå†…å®¹...")
        
        # ä½¿ç”¨åŸºç¡€æ–¹æ³•ç”Ÿæˆåˆå§‹æŠ¥å‘Š
        base_report = self.generate_complete_report(
            subject_name=subject_name,
            outline_data=outline_data,
            allocation_result=allocation_result,
            all_flattened_data=all_flattened_data,
            visualization_results=visualization_results,
            output_file=None 
        )
        
        print("âœ… åŸºç¡€æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        # ====== ç¬¬äºŒè½®ï¼šå¯è§†åŒ–å¢å¼º ======
        print(f"\nğŸ¨ ç¬¬äºŒè½®ï¼šåŠ è½½å¯è§†åŒ–èµ„æºå¹¶å¢å¼ºå†…å®¹...")
        
        # åŠ è½½å¯è§†åŒ–èµ„æº
        visualization_resources = self.content_assembler.load_visualization_resources(
            images_dir=images_dir,
            target_name=subject_name,
            name_field='company_name'  # å…¬å¸ç ”æŠ¥ä½¿ç”¨company_nameå­—æ®µ
        )
        
        if not visualization_resources:
            print("âš ï¸ æœªæ‰¾åˆ°å¯è§†åŒ–èµ„æºï¼Œè¿”å›åŸºç¡€æŠ¥å‘Š")
            if output_file:
                self._save_report(base_report, output_file)
            return base_report
        
        # è¯¦ç»†æ‰“å°å¯è§†åŒ–èµ„æºåˆ†é…æƒ…å†µ
        print(f"\nğŸ¯ \033[93må¯è§†åŒ–èµ„æºåˆ†é…åˆ†æï¼š\033[0m")
        print(f"\033[93mæ€»å…±åŠ è½½äº† {len(visualization_resources)} ä¸ªç« èŠ‚çš„å¯è§†åŒ–èµ„æº\033[0m")
        
        # åˆ†ææ¯ä¸ªç« èŠ‚çš„åŒ¹é…æƒ…å†µ
        original_sections = base_report.get("sections", [])
        for section in original_sections:
            section_title = section.get("section_title", "")
            matching_charts = visualization_resources.get(section_title, [])
            
            if matching_charts:
                print(f"\033[93mâœ… ç« èŠ‚ '{section_title}' æ‰¾åˆ° {len(matching_charts)} ä¸ªå›¾è¡¨ï¼š\033[0m")
                for i, chart in enumerate(matching_charts, 1):
                    chart_title = chart.get('chart_title', f'å›¾è¡¨{i}')
                    chart_type = chart.get('chart_type', 'æœªçŸ¥')
                    png_path = chart.get('png_path', '')
                    png_status = "å¯ç”¨" if png_path and os.path.exists(png_path) else "ä¸å¯ç”¨"
                    print(f"\033[93m   {i}. {chart_title} ({chart_type}) - PNG:{png_status}\033[0m")
            else:
                print(f"\033[93mâŒ ç« èŠ‚ '{section_title}' æœªæ‰¾åˆ°åŒ¹é…çš„å›¾è¡¨\033[0m")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªåˆ†é…çš„å¯è§†åŒ–èµ„æº
        unmatched_sections = set(visualization_resources.keys()) - set(s.get("section_title", "") for s in original_sections)
        if unmatched_sections:
            print(f"\n\033[93mâš ï¸ å‘ç° {len(unmatched_sections)} ä¸ªæœªåŒ¹é…çš„å¯è§†åŒ–èµ„æºç« èŠ‚ï¼š\033[0m")
            for section in unmatched_sections:
                charts_count = len(visualization_resources[section])
                print(f"\033[93m   - {section} ({charts_count}ä¸ªå›¾è¡¨)\033[0m")
        
        # å¢å¼ºæ¯ä¸ªç« èŠ‚çš„å†…å®¹
        enhanced_sections = []
        original_sections = base_report.get("sections", [])
        
        print(f"\nğŸ”„ \033[93må¼€å§‹ç« èŠ‚å†…å®¹å¢å¼ºï¼ˆå…±{len(original_sections)}ä¸ªç« èŠ‚ï¼‰ï¼š\033[0m")
        
        for idx, section in enumerate(original_sections, 1):
            section_title = section.get("section_title", "")
            original_content = section.get("content", "")
            
            print(f"\n\033[93mğŸ“ [{idx}/{len(original_sections)}] å¤„ç†ç« èŠ‚: {section_title}\033[0m")
            
            # ç›´æ¥ä½¿ç”¨åŸºç¡€ç»„è£…å™¨çš„ç« èŠ‚åŒ¹é…é€»è¾‘ï¼Œä¸éœ€è¦è‡ªå®šä¹‰åŒ¹é…
            # åŸºç¡€ç»„è£…å™¨å·²ç»æŒ‰sectionå­—æ®µåˆ†ç»„äº†å¯è§†åŒ–èµ„æº
            matching_charts = visualization_resources.get(section_title, [])
            
            if matching_charts:
                print(f"\033[93m   ğŸ¯ å‘ç° {len(matching_charts)} ä¸ªåŒ¹é…å›¾è¡¨ï¼š\033[0m")
                for i, chart in enumerate(matching_charts, 1):
                    chart_title = chart.get('chart_title', f'å›¾è¡¨{i}')
                    chart_type = chart.get('chart_type', 'æœªçŸ¥')
                    png_path = chart.get('png_path', '')
                    png_status = "âœ…å¯ç”¨" if png_path and os.path.exists(png_path) else "âŒä¸å¯ç”¨"
                    print(f"\033[93m      {i}. {chart_title} ({chart_type}) {png_status}\033[0m")
                
                # ç”Ÿæˆå¢å¼ºå†…å®¹
                print(f"\033[93m   ğŸ¨ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å¢å¼ºå†…å®¹...\033[0m")
                enhanced_content = self.content_assembler.generate_section_with_visualization(
                    section_title=section_title,
                    original_content=original_content,
                    visualization_charts=matching_charts,
                    llm_call_function=self._call_llm,
                    target_name=subject_name,
                    api_key=self.api_key,
                    base_url=self.base_url,
                    model=self.model,
                    enable_text_visualization=True,
                    output_dir=images_dir
                )
                
                # ç»Ÿè®¡å†…å®¹æ”¹å–„æƒ…å†µ
                original_length = len(original_content)
                enhanced_length = len(enhanced_content)
                improvement_ratio = (enhanced_length - original_length) / original_length if original_length > 0 else 0
                
                print(f"\033[93m   ğŸ“ˆ å†…å®¹å¢å¼ºå®Œæˆ: {original_length} â†’ {enhanced_length} å­—ç¬¦ (+{improvement_ratio:.1%})\033[0m")
                
                # æ›´æ–°ç« èŠ‚ä¿¡æ¯
                enhanced_section = section.copy()
                enhanced_section["content"] = enhanced_content
                enhanced_section["visualization_charts"] = matching_charts
                enhanced_section["charts_count"] = len(matching_charts)
                enhanced_section["enhanced"] = True
                enhanced_section["content_stats"] = {
                    "original_length": original_length,
                    "enhanced_length": enhanced_length,
                    "improvement_ratio": improvement_ratio
                }
                
                enhanced_sections.append(enhanced_section)
            else:
                print(f"\033[93m   â– æ— åŒ¹é…å›¾è¡¨ï¼Œå°è¯•åŸºäºæ–‡æœ¬ç”Ÿæˆå¯è§†åŒ–...\033[0m")
                
                # å³ä½¿æ²¡æœ‰é¢„è®¾å›¾è¡¨ï¼Œä¹Ÿå°è¯•åŸºäºæ–‡æœ¬ç”Ÿæˆå¯è§†åŒ–
                enhanced_content = self.content_assembler.generate_section_with_visualization(
                    section_title=section_title,
                    original_content=original_content,
                    visualization_charts=[],  # ç©ºåˆ—è¡¨ï¼Œè®©æ–¹æ³•è‡ªåŠ¨ç”Ÿæˆæ–‡æœ¬å¯è§†åŒ–
                    llm_call_function=self._call_llm,
                    target_name=subject_name,
                    api_key=self.api_key,
                    base_url=self.base_url,
                    model=self.model,
                    enable_text_visualization=True,
                    output_dir=images_dir  # ä½¿ç”¨ä¼ å…¥çš„images_dirå‚æ•°
                )
                
                # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†æ–°çš„å¯è§†åŒ–å†…å®¹
                if enhanced_content != original_content:
                    enhanced_section = section.copy()
                    enhanced_section["content"] = enhanced_content
                    enhanced_section["enhanced"] = True
                    enhanced_section["generation_method"] = "text_visualization"
                    enhanced_sections.append(enhanced_section)
                    print(f"\033[93m   âœ… åŸºäºæ–‡æœ¬ç”Ÿæˆäº†å¯è§†åŒ–å†…å®¹\033[0m")
                else:
                    section["enhanced"] = False
                    enhanced_sections.append(section)
                    print(f"\033[93m   â– æ–‡æœ¬å¯è§†åŒ–ç”Ÿæˆå¤±è´¥ï¼Œä¿æŒåŸå†…å®¹\033[0m")
        
        # åˆ›å»ºå¢å¼ºæŠ¥å‘Š
        enhanced_report = base_report.copy()
        enhanced_report["sections"] = enhanced_sections
        enhanced_report["enhancement_stats"] = self._calculate_enhancement_stats(enhanced_sections)
        
        print("âœ… å†…å®¹å¢å¼ºå®Œæˆ")
        
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        if output_file:
            self._save_report(enhanced_report, output_file)
        
        print(f"ğŸ‰ {subject_name} å¯è§†åŒ–å¢å¼ºç ”ç©¶æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        return enhanced_report
    
    async def generate_complete_report_with_visualization_async(
        self,
        subject_name: str,
        outline_data: Dict[str, Any],
        allocation_result: Dict[str, Any],
        all_flattened_data: List[Dict[str, Any]],
        images_dir: str,
        visualization_results: Dict[str, Any] = None,
        output_file: str = None,
        max_concurrent: int = 190
    ) -> Dict[str, Any]:
        """
        å¼‚æ­¥ç”Ÿæˆå¸¦æœ‰å¯è§†åŒ–å¢å¼ºçš„å®Œæ•´ç ”ç©¶æŠ¥å‘Šï¼ˆé«˜å¹¶å‘ç‰ˆæœ¬ï¼‰
        
        Args:
            subject_name: ç ”ç©¶ä¸»ä½“åç§°ï¼ˆå…¬å¸åï¼‰
            outline_data: å¤§çº²æ•°æ®
            allocation_result: æ•°æ®åˆ†é…ç»“æœ
            all_flattened_data: æ‰€æœ‰å±•å¹³æ•°æ®
            images_dir: å›¾ç‰‡ç›®å½•è·¯å¾„
            visualization_results: å¯è§†åŒ–ç»“æœï¼ˆå¯é€‰ï¼‰
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼Œé»˜è®¤190
            
        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šå†…å®¹
        """
        print(f"\nğŸš€ å¼€å§‹é«˜å¹¶å‘ç”Ÿæˆ {subject_name} å¯è§†åŒ–å¢å¼ºç ”ç©¶æŠ¥å‘Šï¼ˆå¹¶å‘æ•°: {max_concurrent}ï¼‰...")
        
        # ====== ç¬¬ä¸€è½®ï¼šå¼‚æ­¥ç”ŸæˆåŸºç¡€å†…å®¹ ======
        print("\nğŸ”„ ç¬¬ä¸€è½®ï¼šå¼‚æ­¥ç”ŸæˆåŸºç¡€æŠ¥å‘Šå†…å®¹...")
        
        # é‡ç½®å‚è€ƒæ–‡çŒ®çŠ¶æ€
        self.content_assembler.reset_references()
        
        # ä½¿ç”¨æ•°æ®å¤„ç†å™¨ç¡®å®šæœ‰æ•°æ®çš„ç« èŠ‚
        sections_with_data = self.data_processor.determine_sections_with_data(
            outline_data, allocation_result, visualization_results
        )
        print(f"ğŸ“‹ æŠ¥å‘ŠåŒ…å« {len(sections_with_data)} ä¸ªç« èŠ‚")
        
        # å‡†å¤‡ç« èŠ‚æ•°æ®è¿›è¡Œå¹¶å‘å¤„ç†
        sections_data = []
        for i, section_info in enumerate(sections_with_data):
            section_title = section_info["title"]
            section_points = section_info["points"]
            allocated_data_ids = section_info["allocated_data_ids"]
            allocated_charts = section_info.get("allocated_charts", [])
            
            # æ”¶é›†ç« èŠ‚ç›¸å…³æ•°æ®
            collected_data_info = self.data_collector.collect_data_for_section(
                section_title=section_title,
                section_points=section_points,
                allocated_data_ids=allocated_data_ids,
                all_data=all_flattened_data,
                max_context_tokens=self.available_tokens,
                company_name=subject_name
            )
            
            sections_data.append({
                "section_index": section_info["index"],
                "section_title": section_title,
                "section_points": section_points,
                "collected_data_info": collected_data_info,
                "allocated_charts": allocated_charts,
                "processing_method": collected_data_info["processing_method"],
                "subject_name": subject_name
            })
        
        # ä½¿ç”¨content_assemblerçš„å¼‚æ­¥æ‰¹é‡å¤„ç†æ–¹æ³•
        print(f"ğŸ“‹ å‡†å¤‡å¼‚æ­¥å¤„ç† {len(sections_data)} ä¸ªç« èŠ‚...")
        
        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(max_concurrent // 2)  # ç¬¬ä¸€è½®ä½¿ç”¨ä¸€åŠå¹¶å‘
        
        async def generate_single_section(section_data: Dict[str, Any]) -> Dict[str, Any]:
            """å¼‚æ­¥ç”Ÿæˆå•ä¸ªç« èŠ‚å†…å®¹"""
            async with semaphore:
                section_title = section_data["section_title"]
                section_points = section_data["section_points"]
                collected_data_info = section_data["collected_data_info"]
                allocated_charts = section_data["allocated_charts"]
                processing_method = section_data["processing_method"]
                
                print(f"\033[94mğŸ“ ç”Ÿæˆç« èŠ‚ï¼š{section_title} ({processing_method})\033[0m")
                
                # æ ¹æ®å¤„ç†æ–¹æ³•ç”Ÿæˆå†…å®¹
                if processing_method == "no_data":
                    # æ— æ•°æ®æ”¯æ’‘ï¼Œç”ŸæˆåŸºç¡€æ¡†æ¶
                    section_info = {
                        "title": section_title,
                        "points": section_points
                    }
                    content = await self._generate_section_without_data_async(section_info, subject_name)
                else:
                    # æœ‰æ•°æ®æ”¯æ’‘ï¼Œç”Ÿæˆè¯¦ç»†å†…å®¹
                    section_info = {
                        "title": section_title,
                        "points": section_points,
                        "allocated_charts": allocated_charts
                    }
                    content = await self._generate_section_with_data_async(
                        section_info=section_info,
                        collected_data_info=collected_data_info,
                        subject_name=subject_name,
                        report_context={"subject_name": subject_name}
                    )
                
                return {
                    "section_index": section_data["section_index"],
                    "section_title": section_title,
                    "section_points": section_points,
                    "content": content,
                    "data_info": collected_data_info,
                    "allocated_charts": allocated_charts,
                    "charts_count": len(allocated_charts),
                    "generation_method": processing_method,
                    "has_data": processing_method != "no_data"
                }
        
        # å¼‚æ­¥æ‰¹é‡ç”ŸæˆåŸºç¡€å†…å®¹
        print(f"ğŸ”„ å¼€å§‹é«˜å¹¶å‘ç”ŸæˆåŸºç¡€å†…å®¹ï¼ˆ{max_concurrent // 2}å¹¶å‘ï¼‰...")
        tasks = [generate_single_section(section_data) for section_data in sections_data]
        processed_sections = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸æƒ…å†µ
        final_sections = []
        for i, result in enumerate(processed_sections):
            if isinstance(result, Exception):
                print(f"\033[91mâŒ ç« èŠ‚ {i+1} ç”Ÿæˆå¤±è´¥: {result}\033[0m")
                # åˆ›å»ºä¸€ä¸ªé”™è¯¯ç« èŠ‚
                section_data = sections_data[i]
                error_section = {
                    "section_index": section_data["section_index"],
                    "section_title": section_data["section_title"],
                    "content": f"ç« èŠ‚ç”Ÿæˆå¤±è´¥: {str(result)}",
                    "error": str(result),
                    "has_data": False
                }
                final_sections.append(error_section)
            else:
                final_sections.append(result)
        
        # åˆ›å»ºåŸºç¡€æŠ¥å‘Š
        base_report = {
            "subject_name": subject_name,
            "report_type": "company_research",
            "sections": processed_sections,
            "generation_stats": {
                "total_sections": len(processed_sections),
                "sections_with_data": sum(1 for s in processed_sections if s.get("has_data", False)),
                "sections_without_data": sum(1 for s in processed_sections if not s.get("has_data", False)),
                "total_words": sum(len(s.get("content", "")) for s in processed_sections),
                "total_references": len(self.content_assembler.global_references)
            }
        }
        
        print("âœ… åŸºç¡€æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        # ====== ç¬¬äºŒè½®ï¼šå¼‚æ­¥å¯è§†åŒ–å¢å¼º ======
        print(f"\nğŸ¨ ç¬¬äºŒè½®ï¼šå¼‚æ­¥åŠ è½½å¯è§†åŒ–èµ„æºå¹¶å¢å¼ºå†…å®¹...")
        
        # å¼‚æ­¥åŠ è½½å¯è§†åŒ–èµ„æº
        visualization_resources = await self.content_assembler.load_visualization_resources_async(
            images_dir=images_dir,
            target_name=subject_name,
            name_field='company_name'
        )
        
        if not visualization_resources:
            print("âš ï¸ æœªæ‰¾åˆ°å¯è§†åŒ–èµ„æºï¼Œè¿”å›åŸºç¡€æŠ¥å‘Š")
            if output_file:
                await self._save_report_async(base_report, output_file)
            return base_report
        
        # è¯¦ç»†æ‰“å°å¯è§†åŒ–èµ„æºåˆ†é…æƒ…å†µ
        print(f"\nğŸ¯ \033[93må¯è§†åŒ–èµ„æºåˆ†é…åˆ†æï¼š\033[0m")
        print(f"\033[93mæ€»å…±åŠ è½½äº† {len(visualization_resources)} ä¸ªç« èŠ‚çš„å¯è§†åŒ–èµ„æº\033[0m")
        
        # å‡†å¤‡å¯è§†åŒ–å¢å¼ºçš„ç« èŠ‚æ•°æ®
        enhancement_sections_data = []
        for section in processed_sections:
            section_title = section.get("section_title", "")
            original_content = section.get("content", "")
            matching_charts = visualization_resources.get(section_title, [])
            
            enhancement_sections_data.append({
                "section_title": section_title,
                "original_content": original_content,
                "visualization_charts": matching_charts,
                "section_data": section  # ä¿å­˜åŸå§‹ç« èŠ‚æ•°æ®
            })
        
        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def enhance_single_section(section_data: Dict[str, Any]) -> Dict[str, Any]:
            async with semaphore:
                section_title = section_data["section_title"]
                original_content = section_data["original_content"]
                matching_charts = section_data["visualization_charts"]
                original_section = section_data["section_data"]
                
                print(f"\033[93mğŸ¨ [{asyncio.current_task().get_name()}] å¤„ç†ç« èŠ‚: {section_title}\033[0m")
                
                if matching_charts:
                    print(f"\033[93m   ğŸ¯ å‘ç° {len(matching_charts)} ä¸ªåŒ¹é…å›¾è¡¨\033[0m")
                    
                    # å¼‚æ­¥ç”Ÿæˆå¢å¼ºå†…å®¹
                    enhanced_content = await self.content_assembler.generate_section_with_visualization_async(
                        section_title=section_title,
                        original_content=original_content,
                        visualization_charts=matching_charts,
                        llm_call_function_async=self._call_llm_async,
                        target_name=subject_name,
                        api_key=self.api_key,
                        base_url=self.base_url,
                        model=self.model,
                        enable_text_visualization=True,
                        output_dir=images_dir
                    )
                    
                    # ç»Ÿè®¡å†…å®¹æ”¹å–„æƒ…å†µ
                    original_length = len(original_content)
                    enhanced_length = len(enhanced_content)
                    improvement_ratio = (enhanced_length - original_length) / original_length if original_length > 0 else 0
                    
                    print(f"\033[93m   ğŸ“ˆ å†…å®¹å¢å¼ºå®Œæˆ: {original_length} â†’ {enhanced_length} å­—ç¬¦ (+{improvement_ratio:.1%})\033[0m")
                    
                    # æ›´æ–°ç« èŠ‚ä¿¡æ¯
                    enhanced_section = original_section.copy()
                    enhanced_section["content"] = enhanced_content
                    enhanced_section["visualization_charts"] = matching_charts
                    enhanced_section["charts_count"] = len(matching_charts)
                    enhanced_section["enhanced"] = True
                    enhanced_section["content_stats"] = {
                        "original_length": original_length,
                        "enhanced_length": enhanced_length,
                        "improvement_ratio": improvement_ratio
                    }
                    
                    return enhanced_section
                else:
                    print(f"\033[93m   â– æ— åŒ¹é…å›¾è¡¨ï¼Œå°è¯•åŸºäºæ–‡æœ¬ç”Ÿæˆå¯è§†åŒ–...\033[0m")
                    
                    # å¼‚æ­¥ç”Ÿæˆæ–‡æœ¬å¯è§†åŒ–
                    enhanced_content = await self.content_assembler.generate_section_with_visualization_async(
                        section_title=section_title,
                        original_content=original_content,
                        visualization_charts=[],
                        llm_call_function_async=self._call_llm_async,
                        target_name=subject_name,
                        api_key=self.api_key,
                        base_url=self.base_url,
                        model=self.model,
                        enable_text_visualization=True,
                        output_dir=images_dir
                    )
                    
                    # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†æ–°çš„å¯è§†åŒ–å†…å®¹
                    if enhanced_content != original_content:
                        enhanced_section = original_section.copy()
                        enhanced_section["content"] = enhanced_content
                        enhanced_section["enhanced"] = True
                        enhanced_section["generation_method"] = "text_visualization"
                        print(f"\033[93m   âœ… åŸºäºæ–‡æœ¬ç”Ÿæˆäº†å¯è§†åŒ–å†…å®¹\033[0m")
                        return enhanced_section
                    else:
                        original_section["enhanced"] = False
                        print(f"\033[93m   â– æ–‡æœ¬å¯è§†åŒ–ç”Ÿæˆå¤±è´¥ï¼Œä¿æŒåŸå†…å®¹\033[0m")
                        return original_section
        
        # é«˜å¹¶å‘å¤„ç†æ‰€æœ‰ç« èŠ‚
        print(f"\nğŸ”„ \033[93må¼€å§‹é«˜å¹¶å‘ç« èŠ‚å¢å¼ºï¼ˆ{max_concurrent}å¹¶å‘ï¼Œå…±{len(enhancement_sections_data)}ä¸ªç« èŠ‚ï¼‰ï¼š\033[0m")
        
        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        tasks = []
        for i, section_data in enumerate(enhancement_sections_data):
            task = asyncio.create_task(
                enhance_single_section(section_data),
                name=f"enhance-section-{i+1}"
            )
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        enhanced_sections = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸æƒ…å†µ
        final_enhanced_sections = []
        for i, result in enumerate(enhanced_sections):
            if isinstance(result, Exception):
                print(f"\033[91mâŒ ç« èŠ‚ {i+1} å¤„ç†å¤±è´¥: {result}\033[0m")
                # ä½¿ç”¨åŸå§‹ç« èŠ‚ä½œä¸ºå¤‡é€‰
                original_section = enhancement_sections_data[i]["section_data"]
                original_section["enhanced"] = False
                original_section["error"] = str(result)
                final_enhanced_sections.append(original_section)
            else:
                final_enhanced_sections.append(result)
        
        # åˆ›å»ºå¢å¼ºæŠ¥å‘Š
        enhanced_report = base_report.copy()
        enhanced_report["sections"] = final_enhanced_sections
        enhanced_report["enhancement_stats"] = self._calculate_enhancement_stats(final_enhanced_sections)
        
        print("âœ… é«˜å¹¶å‘å†…å®¹å¢å¼ºå®Œæˆ")
        
        # å¼‚æ­¥ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        if output_file:
            await self._save_report_async(enhanced_report, output_file)
        
        print(f"ğŸ‰ {subject_name} é«˜å¹¶å‘å¯è§†åŒ–å¢å¼ºç ”ç©¶æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        return enhanced_report
    
    def _call_llm(self, prompt: str) -> str:
        """
        è°ƒç”¨LLMç”Ÿæˆå†…å®¹
        
        Args:
            prompt: æç¤ºè¯
            
        Returns:
            ç”Ÿæˆçš„å†…å®¹
        """
        return chat_no_tool(
            user_content=prompt,
            api_key=self.api_key,
            base_url=self.base_url,
            model=self.model
        )
    
    async def _call_llm_async(self, prompt: str) -> str:
        """
        å¼‚æ­¥è°ƒç”¨LLMç”Ÿæˆå†…å®¹
        
        Args:
            prompt: æç¤ºè¯
            
        Returns:
            ç”Ÿæˆçš„å†…å®¹
        """
        # åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡ŒåŒæ­¥çš„chat_no_tool
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None,
            lambda: chat_no_tool(
                user_content=prompt,
                api_key=self.api_key,
                base_url=self.base_url,
                model=self.model
            )
        )
    
    async def _generate_section_without_data_async(
        self,
        section_info: Dict[str, Any],
        subject_name: str
    ) -> str:
        """
        å¼‚æ­¥ä¸ºæ— æ•°æ®æ”¯æ’‘çš„ç« èŠ‚ç”ŸæˆåŸºç¡€æ¡†æ¶
        
        Args:
            section_info: ç« èŠ‚ä¿¡æ¯
            subject_name: ç ”ç©¶ä¸»ä½“åç§°
            
        Returns:
            ç”Ÿæˆçš„ç« èŠ‚å†…å®¹
        """
        section_title = section_info["title"]
        section_points = section_info["points"]
        
        # æ„å»ºè¦ç‚¹æ–‡æœ¬
        points_text = "\\n".join([f"- {point}" for point in section_points])
        
        # ä½¿ç”¨æ— æ•°æ®æç¤ºè¯æ¨¡æ¿
        prompt = self.get_section_without_data_prompt().format(
            subject_name=subject_name,
            section_title=section_title,
            points_text=points_text
        )
        
        return await self._call_llm_async(prompt)
    
    async def _generate_section_with_data_async(
        self,
        section_info: Dict[str, Any],
        collected_data_info: Dict[str, Any],
        subject_name: str,
        report_context: Dict[str, Any]
    ) -> str:
        """
        å¼‚æ­¥ä¸ºæœ‰æ•°æ®æ”¯æ’‘çš„ç« èŠ‚ç”Ÿæˆå†…å®¹
        
        Args:
            section_info: ç« èŠ‚ä¿¡æ¯
            collected_data_info: æ”¶é›†åˆ°çš„æ•°æ®ä¿¡æ¯
            subject_name: ç ”ç©¶ä¸»ä½“åç§°
            report_context: æŠ¥å‘Šä¸Šä¸‹æ–‡
            
        Returns:
            ç”Ÿæˆçš„ç« èŠ‚å†…å®¹
        """
        section_title = section_info["title"]
        section_points = section_info["points"]
        allocated_charts = section_info.get("allocated_charts", [])
        
        # æ„å»ºè¦ç‚¹æ–‡æœ¬
        points_text = "\\n".join([f"- {point}" for point in section_points])
        
        # æ„å»ºæ•°æ®å†…å®¹
        data_content = self.content_assembler.build_data_content(
            collected_data_info, 
            collected_data_info["processing_method"]
        )
        
        # æ„å»ºå›¾è¡¨å†…å®¹
        chart_content = self.content_assembler.build_chart_content(allocated_charts)
        
        # ä½¿ç”¨æœ‰æ•°æ®æç¤ºè¯æ¨¡æ¿
        prompt = self.get_section_with_data_prompt().format(
            subject_name=subject_name,
            section_title=section_title,
            points_text=points_text,
            data_content=data_content,
            chart_content=chart_content
        )
        
        return await self._call_llm_async(prompt)
    
    def _save_report(self, report: Dict[str, Any], output_file: str):
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        
        Args:
            report: æŠ¥å‘Šæ•°æ®
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if output_file.lower().endswith(".md"):
            markdown_content = self.content_assembler.assemble_markdown_report(report)
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(markdown_content)
            print(f"ğŸ“ Markdown æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        else:
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
    
    async def _save_report_async(self, report: Dict[str, Any], output_file: str):
        """
        å¼‚æ­¥ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        
        Args:
            report: æŠ¥å‘Šæ•°æ®
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        loop = asyncio.get_event_loop()
        
        def _sync_save():
            if output_file.lower().endswith(".md"):
                markdown_content = self.content_assembler.assemble_markdown_report(report)
                with open(output_file, "w", encoding="utf-8") as f:
                    f.write(markdown_content)
                return f"ğŸ“ Markdown æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}"
            else:
                with open(output_file, "w", encoding="utf-8") as f:
                    json.dump(report, f, ensure_ascii=False, indent=2)
                return f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}"
        
        message = await loop.run_in_executor(None, _sync_save)
        print(message)
    
    def _calculate_enhancement_stats(self, sections: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è®¡ç®—å¢å¼ºç»Ÿè®¡ä¿¡æ¯
        
        Args:
            sections: ç« èŠ‚åˆ—è¡¨
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        total_sections = len(sections)
        enhanced_sections = sum(1 for s in sections if s.get("enhanced", False))
        total_charts = sum(s.get("charts_count", 0) for s in sections)
        
        # è®¡ç®—å†…å®¹æ”¹å–„ç»Ÿè®¡
        total_original_length = 0
        total_enhanced_length = 0
        
        for section in sections:
            content_stats = section.get("content_stats", {})
            total_original_length += content_stats.get("original_length", 0)
            total_enhanced_length += content_stats.get("enhanced_length", 0)
        
        overall_improvement = 0
        if total_original_length > 0:
            overall_improvement = (total_enhanced_length - total_original_length) / total_original_length
        
        return {
            "total_sections": total_sections,
            "enhanced_sections": enhanced_sections,
            "enhancement_rate": enhanced_sections / total_sections if total_sections > 0 else 0,
            "total_charts": total_charts,
            "content_improvement": {
                "total_original_length": total_original_length,
                "total_enhanced_length": total_enhanced_length,
                "overall_improvement_ratio": overall_improvement,
                "avg_charts_per_enhanced_section": total_charts / enhanced_sections if enhanced_sections > 0 else 0
            }
        }


if __name__ == "__main__":
    """ä¸»ç¨‹åºå…¥å£ - ç”Ÿæˆå…¬å¸ç ”ç©¶æŠ¥å‘Š"""
    
    # å¯¼å…¥osæ¨¡å—ç”¨äºè·¯å¾„å¤„ç†
    import os
    from dotenv import load_dotenv
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # ====== APIé…ç½® - ä¸ company_collection_data.py ä¿æŒä¸€è‡´ ======
    api_key = os.getenv("GUIJI_API_KEY")
    base_url = os.getenv("GUIJI_BASE_URL")
    model = os.getenv("GUIJI_TEXT_MODEL_DEEPSEEK_PRO")  # ä½¿ç”¨é«˜çº§æ¨¡å‹
    
    if not all([api_key, base_url, model]):
        print("âŒ ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡é…ç½®:")
        print("   - GUIJI_API_KEY")
        print("   - GUIJI_BASE_URL") 
        print("   - GUIJI_TEXT_MODEL_DEEPSEEK_PRO")
        print("ğŸ’¡ è¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®")
        exit(1)
    
    # æ•°æ®æ–‡ä»¶è·¯å¾„é…ç½®
    data_files = {
        "outline_file": "test_company_datas/company_outline.json",
        "allocation_result_file": "test_company_datas/outline_data_allocation.json",
        "enhanced_allocation_file": "test_company_datas/enhanced_allocation_result.json",
        "flattened_data_file": "test_company_datas/flattened_tonghuashun_data.json",
        "visualization_results_file": "test_company_datas/visual_enhancement_results.json",
        "output_file": "test_company_datas/generated_report.md"
    }
    
    # å…¬å¸åç§°å’Œè¾“å‡ºç›®å½•é…ç½®
    company_name = "4Paradigm"
    
    # ====== è¾“å‡ºç›®å½•é…ç½® ======
    # ä¸ company_collection_data.py ä¿æŒä¸€è‡´çš„è·¯å¾„é…ç½®
    images_dir = os.path.join("test_company_datas", "images")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if not os.path.exists(images_dir):
        os.makedirs(images_dir, exist_ok=True)
        print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {images_dir}")
    
    print(f"ğŸ“ å›¾è¡¨è¾“å‡ºç›®å½•: {images_dir}")
    print(f"ğŸ”‘ ä½¿ç”¨APIé…ç½®: {base_url} / {model}")
    
    async def main():
        """å¼‚æ­¥ä¸»å‡½æ•° - æ”¯æŒ190å¹¶å‘"""
        try:
            print("ğŸ“‚ åŠ è½½æ•°æ®æ–‡ä»¶...")
            
            # ä½¿ç”¨ä¸collectionè„šæœ¬ç›¸åŒçš„APIé…ç½®
            generator = CompanyReportGenerator(
                api_key=api_key,
                base_url=base_url,
                model=model,
                max_context_tokens=128 * 1024 * 0.8 # è®¾ç½®ä¸º80%ä¸Šä¸‹æ–‡é™åˆ¶
            )
            outline_data, allocation_result, flattened_data, visualization_results = generator.load_report_data(
                **{k: v for k, v in data_files.items() if k != "output_file"}
            )
            print("âœ… æ•°æ®åŠ è½½å®Œæˆ")
            
            print(f"ğŸš€ å¼€å§‹é«˜å¹¶å‘ç”Ÿæˆ {company_name} å¯è§†åŒ–å¢å¼ºç ”ç©¶æŠ¥å‘Šï¼ˆ190å¹¶å‘ï¼‰...")
            
            # ä½¿ç”¨æ–°çš„é«˜å¹¶å‘å¯è§†åŒ–å¢å¼ºæ–¹æ³•
            report = await generator.generate_complete_report_with_visualization_async(
                subject_name=company_name,
                outline_data=outline_data,
                allocation_result=allocation_result,
                all_flattened_data=flattened_data,
                images_dir=images_dir,
                visualization_results=visualization_results,
                output_file=data_files["output_file"],
                max_concurrent=190  # è®¾ç½®190å¹¶å‘
            )
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“Š æŠ¥å‘Šç”Ÿæˆç»Ÿè®¡:")
            stats = report.get("generation_stats", {})
            enhancement_stats = report.get("enhancement_stats", {})
            
            print(f"   - æ€»ç« èŠ‚æ•°: {stats.get('total_sections', len(report.get('sections', [])))}")
            print(f"   - æœ‰æ•°æ®æ”¯æ’‘: {stats.get('sections_with_data', 0)}")
            print(f"   - æ— æ•°æ®ç« èŠ‚: {stats.get('sections_without_data', 0)}")
            print(f"   - æ€»å­—æ•°: {stats.get('total_words', 0):,}")
            print(f"   - å‚è€ƒæ–‡çŒ®æ•°: {stats.get('total_references', 0)}")
            
            # å¯è§†åŒ–å¢å¼ºç»Ÿè®¡
            if enhancement_stats:
                print(f"\nğŸ¨ å¯è§†åŒ–å¢å¼ºç»Ÿè®¡:")
                print(f"   - å¢å¼ºç« èŠ‚æ•°: {enhancement_stats.get('enhanced_sections', 0)}")
                print(f"   - å¢å¼ºè¦†ç›–ç‡: {enhancement_stats.get('enhancement_rate', 0):.1%}")
                print(f"   - æ€»å›¾è¡¨æ•°: {enhancement_stats.get('total_charts', 0)}")
                
                # å†…å®¹æ”¹å–„ç»Ÿè®¡
                content_improvement = enhancement_stats.get('content_improvement', {})
                if content_improvement:
                    print(f"\nğŸ“ˆ å†…å®¹æ”¹å–„ç»Ÿè®¡:")
                    original_len = content_improvement.get('total_original_length', 0)
                    enhanced_len = content_improvement.get('total_enhanced_length', 0)
                    improvement_ratio = content_improvement.get('overall_improvement_ratio', 0)
                    avg_charts = content_improvement.get('avg_charts_per_enhanced_section', 0)
                    
                    print(f"   - åŸå§‹æ€»å­—ç¬¦æ•°: {original_len:,}")
                    print(f"   - å¢å¼ºåå­—ç¬¦æ•°: {enhanced_len:,}")
                    print(f"   - æ•´ä½“å†…å®¹å¢é•¿: {improvement_ratio:.1%}")
                    print(f"   - å¹³å‡æ¯ç« èŠ‚å›¾è¡¨æ•°: {avg_charts:.1f}")
            
            print(f"\nğŸ‰ é«˜å¹¶å‘å¯è§†åŒ–å¢å¼ºæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {data_files['output_file']}")
            print(f"ğŸ’¡ æç¤º: æŠ¥å‘Šä¸­å›¾è¡¨å·²è‡ªåŠ¨åµŒå…¥markdownæ ¼å¼ï¼Œå¯ç›´æ¥é¢„è§ˆ")
            
            # å¯é€‰ï¼šåŒæ—¶ç”Ÿæˆæ ‡å‡†ç‰ˆæœ¬è¿›è¡Œå¯¹æ¯”
            print(f"\nğŸ“‹ ç”Ÿæˆæ ‡å‡†ç‰ˆæœ¬ç”¨äºå¯¹æ¯”...")
            standard_output = data_files["output_file"].replace(".md", "_standard.md")
            
            # ä½¿ç”¨åŒæ­¥æ–¹æ³•ç”Ÿæˆæ ‡å‡†ç‰ˆæœ¬
            standard_report = generator.generate_complete_report(
                subject_name=company_name,
                outline_data=outline_data,
                allocation_result=allocation_result,
                all_flattened_data=flattened_data,
                visualization_results=visualization_results,
                output_file=standard_output
            )
            print(f"ğŸ“ æ ‡å‡†ç‰ˆæœ¬: {standard_output}")
            
        except FileNotFoundError as e:
            print(f"âŒ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
            print("ğŸ’¡ è¯·å…ˆè¿è¡Œæ•°æ®æ”¶é›†è„šæœ¬ç”Ÿæˆå¿…è¦çš„æ•°æ®æ–‡ä»¶")
        except ValueError as e:
            print(f"âŒ é…ç½®é”™è¯¯: {e}")
            print("ğŸ’¡ è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®")
        except Exception as e:
            print(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    print("ğŸš€ å¯åŠ¨é«˜å¹¶å‘æ¨¡å¼ï¼ˆ190å¹¶å‘ï¼‰...")
    asyncio.run(main())


def run_high_concurrency_mode(max_concurrent: int = 190):
    """
    è¿è¡Œé«˜å¹¶å‘æ¨¡å¼çš„ä¾¿æ·å‡½æ•°
    
    Args:
        max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼Œé»˜è®¤190
    """
    print(f"ğŸš€ å¯åŠ¨é«˜å¹¶å‘æ¨¡å¼ï¼ˆ{max_concurrent}å¹¶å‘ï¼‰...")
    
    # å¯¼å…¥osæ¨¡å—ç”¨äºè·¯å¾„å¤„ç†
    import os
    from dotenv import load_dotenv
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # ====== APIé…ç½® ======
    api_key = os.getenv("GUIJI_API_KEY")
    base_url = os.getenv("GUIJI_BASE_URL")
    model = os.getenv("GUIJI_TEXT_MODEL_DEEPSEEK_PRO")
    
    if not all([api_key, base_url, model]):
        print("âŒ ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡é…ç½®")
        return
    
    # æ•°æ®æ–‡ä»¶è·¯å¾„é…ç½®
    data_files = {
        "outline_file": "test_company_datas/company_outline.json",
        "allocation_result_file": "test_company_datas/outline_data_allocation.json",
        "enhanced_allocation_file": "test_company_datas/enhanced_allocation_result.json",
        "flattened_data_file": "test_company_datas/flattened_tonghuashun_data.json",
        "visualization_results_file": "test_company_datas/visual_enhancement_results.json",
        "output_file": "test_company_datas/generated_report_concurrent.md"
    }
    
    company_name = "4Paradigm"
    images_dir = os.path.join("test_company_datas", "images")
    
    async def concurrent_main():
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¿…è¦çš„æ•°æ®æ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨è¿è¡Œæ•°æ®æ”¶é›†
        missing_files = []
        for key, file_path in data_files.items():
            if key != "output_file" and not os.path.exists(file_path):
                missing_files.append(file_path)
        
        if missing_files:
            print("ğŸ“ åŠ è½½æŠ¥å‘Šç”Ÿæˆæ‰€éœ€æ•°æ®...")
            print("âŒ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå¯åŠ¨è‡ªåŠ¨æ•°æ®æ”¶é›†æµç¨‹...")
            for file_path in missing_files:
                print(f"   - ç¼ºå¤±: {file_path}")
            
            print("\nğŸš€ å¯åŠ¨å…¬å¸æ•°æ®æ”¶é›†æµç¨‹...")
            
            # å¯¼å…¥å¹¶è¿è¡Œæ•°æ®æ”¶é›†
            from data_process.company_data_collection import CompanyDataCollection
            
            # åˆ›å»ºå…¬å¸æ•°æ®æ”¶é›†å™¨
            company_collector = CompanyDataCollection(
                company_name=company_name,
                company_code="06682.HK",  # 4Paradigmçš„è‚¡ç¥¨ä»£ç 
                max_concurrent=190,
                api_key=api_key,
                base_url=base_url,
                model=model,
                use_zhipu_search=True,
                zhipu_search_key=os.getenv("ZHIPU_API_KEY"),
                search_interval=2.0,
                use_existing_search_results=True
            )
            
            # è¿è¡Œæ•°æ®æ”¶é›†æµç¨‹
            print("ğŸ”„ æ­£åœ¨æ”¶é›†å…¬å¸æ•°æ®...")
            collection_results = company_collector.run_full_process()
            
            print(f"âœ… æ•°æ®æ”¶é›†å®Œæˆ!")
            print(f"   - å¤§çº²ç« èŠ‚: {len(collection_results.get('outline_result', {}).get('reportOutline', []))} ä¸ª")
            print(f"   - æ”¶é›†æ•°æ®: {len(collection_results.get('flattened_data', []))} æ¡")
            
            if collection_results.get('visual_enhancement_results'):
                enhancement = collection_results['visual_enhancement_results']
                analysis_phase = enhancement.get('analysis_phase', {})
                suggestions = analysis_phase.get('visualization_suggestions', [])
                print(f"   - å¯è§†åŒ–å»ºè®®: {len(suggestions)} ä¸ª")
            
            if collection_results.get('viz_results'):
                viz_results = collection_results['viz_results']
                chart_results = viz_results.get('chart_generation_results', [])
                successful_charts = [r for r in chart_results if r.get('success', False)]
                print(f"   - ç”Ÿæˆå›¾è¡¨: {len(successful_charts)} ä¸ª")
            
            print("\nğŸ“‚ é‡æ–°åŠ è½½æ•°æ®æ–‡ä»¶...")
        
        generator = CompanyReportGenerator(
            api_key=api_key,
            base_url=base_url,
            model=model,
            max_context_tokens=128 * 1024 * 0.8
        )
        
        outline_data, allocation_result, flattened_data, visualization_results = generator.load_report_data(
            **{k: v for k, v in data_files.items() if k != "output_file"}
        )
        
        report = await generator.generate_complete_report_with_visualization_async(
            subject_name=company_name,
            outline_data=outline_data,
            allocation_result=allocation_result,
            all_flattened_data=flattened_data,
            images_dir=images_dir,
            visualization_results=visualization_results,
            output_file=data_files["output_file"],
            max_concurrent=max_concurrent
        )
        
        print(f"âœ… é«˜å¹¶å‘æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {data_files['output_file']}")
        return report
    
    return asyncio.run(concurrent_main())
